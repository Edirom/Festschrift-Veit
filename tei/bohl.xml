<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="../schemata/cgrid.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="../schemata/cgrid.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main">Dem Igel Sitte lehren  …</title>
            <title type="sub">Musikedition: von der digitalen Verfügbarkeit zur aktiven Nutzung</title>
            <author>
               <name><forename>Benjamin W.</forename> <surname>Bohl</surname></name>
               <email/>
               <affiliation>studierte  nach einem Bachelor of Recording Arts (Honours) an der SAE (Frankfurt am Main und München) Musikwissenschaft an der Julius-Maximilians-Universität Würzburg. Seit seiner Magisterarbeit ist digitale Musikedition sein zentraler Beschäftigungsgegenstand. Als wissenschaftlicher Mitarbeiter am Musikwissenschaftlichen Seminar Detmold/Paderborn sind dabei sowohl grundlegende Forschungsarbeiten zur digitalen Musikedition (<hi rend="italic">Edirom</hi>-Projekt), als auch spezielle inhaltlich-editorische Problemstellungen (<hi rend="italic">Freischütz Digital</hi>, OPERA, <hi rend="italic">Detmolder Hoftheater</hi>) Gegenstand seiner Tätigkeit. Seit Juli 2015 ist er zudem wissenschaftlicher Mitarbeiter am <hi rend="italic">Zentrum für Musik- und Filminformatik</hi> (ZeMFI) im Rahmen des  <hi rend="italic">Zentrum Musik &#x2013; Edition &#x2013; Medien</hi> (ZenMEM). In diesem Kontext liegen seine Forschungsschwerpunkte in den Bereichen interaktive Annotation, Datenmodellierung, und Linked Data.</affiliation>
            </author>
            <author>
               <name><forename>Axel</forename> <surname>Berndt</surname></name>
               <email/>
               <affiliation>hat Informatik mit Nebenfach Musik an der Otto-von-Guericke-Universität Magdeburg studiert. Am dortigen Institut für Simulation und Graphik hat er sich ab 2006 als wissenschftlicher Mitarbeiter auf dem Feld der Musikinformatik betätigt, im Rahmen eines interdisziplinären Forschungsprojektes mit dem Zentrum für Telemann-Pflege und -Forschung Magdeburg kooperiert, die ausdrucksvolle Interpretation und die musikalische Vertonung interaktiver Medien erforscht, 2011 schließlich promoviert. Von 2012 bis 2015 war er als wissenschaftlicher Mitarbeiter an der Technischen Universität Dresden, Fakultät Informatik in Forschung und Lehre im Bereich der Audio- und Musiktechnologie tätig. Seit April 2015 arbeitet Axel Berndt am <hi rend="italic">Zentrum für Musik- und Filminformatik</hi> (ZeMFI) in Detmold. Seine Forschungsinteressen reichen von der musikalischen Mensch-Computer-Interaktion, ausdruckvollen Interpretation, Vertonung interaktiver Medien und generativen Musik bis hin zu Auditory Displays und auditorischen Nutzungsschnittstellen. Die Kooperation zwischen Informatik und Musikwissenschaft ist ein wiederkehrendes Motiv und stetes Anliegen in seinem Schaffen.</affiliation>
            </author>
            <author>
               <name><forename>Simon</forename> <surname>Waloschek</surname></name>
               <email/>
               <affiliation>hat Informatik und Elektrotechnik an der Universität Paderborn studiert und ergänzt aktuell sein akademisches Profil durch ein Studium der Musikübertragung (Tonmeister) an der Hochschule für Musik Detmold.
                  Er ist seit der Gründung 2013 Mitglied des <hi rend="italic">Zentrums für Musik- und Filminformatik</hi> (ZeMFI) und unterstützt darin als wissenschaftlicher Mitarbeiter das <hi rend="italic">Zentrum Musik &#x2013; Edition &#x2013; Medien</hi> (ZenMEM).
                  Seine Forschungsaktivitäten konzentrieren sich vorwiegend auf die musikalische Mensch-Computer-Interaktion. In diesem Rahmen entwickelt er neue Interaktions- und Eingabemodalitäten für Musiker und Musikschaffende.</affiliation>
            </author>
            <author>
               <name><forename>Aristotelis</forename> <surname>Hadjakos</surname></name>
               <email/>
               <affiliation>ist Professor für Musikinformatik an der Hochschule für Musik Detmold. Er leitet das Zentrum für Musik- und Filminformatik, welches eine gemeinsame Einrichtung der Hochschule für Musik Detmold und der Hochschule Ostwestfalen-Lippe ist. Er forscht im Bereich Music Interaction, einer Disziplin, die sich mit dem Design, der Umsetzung und der Untersuchung interaktiver Musiksysteme auseinandersetzt. Seine Forschungsinteressen gelten unter anderem der interaktiven Partitur, Be-greifbaren Musikinterfaces und den Digital Humanities im Bereich Musik und Medien.</affiliation>
            </author>
         </titleStmt>
         <publicationStmt>
            <publisher>Virtueller Forschungsverbund Edirom (ViFE)</publisher>
            <availability>
               <licence target="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License (CC BY 4.0)</licence>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>Converted from a Word document</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <langUsage>
            <language ident="de"/>
         </langUsage>
         <particDesc>
            <listPerson>
               <person xml:id="bohl-pers001">
                  <p>Berlioz, Hector</p>
                  <p n="work" xml:id="bohl-work001"><hi rend="italic">Symphonie fantastique</hi></p>
               </person>
               <person xml:id="bohl-pers002">
                  <p>Chafe, Chris</p>
               </person>
               <person xml:id="bohl-pers003">
                  <p>Chew, Elaine</p>
               </person>
               <person xml:id="bohl-pers004">
                  <p>Estudies, Maximiliano</p>
                  <p n="work" xml:id="bohl-work004"><hi rend="italic">Bild3</hi></p>
               </person>
               <person xml:id="bohl-pers005">
                  <p>Gabrieli, Giovanni</p>
               </person>
               <person xml:id="bohl-pers006">
                  <p>Gurevich, Michael</p>
               </person>
               <person xml:id="bohl-pers011">
                  <p>Kepper, Johannes</p>
               </person>
               <person xml:id="bohl-pers007">
                  <p>Lévy, Fabien</p>
               </person>
               <person xml:id="bohl-pers008">
                  <p>Mauch, Matthias</p>
                  <p n="work" xml:id="bohl-work003"><hi rend="italic">Four tulips, two for you</hi></p>
               </person>
               <person xml:id="bohl-pers009">
                  <p>Maute, Matthias</p>
                  <p n="work" xml:id="bohl-work002"><hi rend="italic">TWINS</hi></p>
               </person>
               <person xml:id="bohl-pers010">
                  <p>Veit, Joachim</p>
               </person>
            </listPerson>
         </particDesc>
      </profileDesc>
      <encodingDesc>
         <tagsDecl>
            <rendition xml:id="bohl-latex-width07">width=.7\textwidth</rendition>
            <rendition xml:id="bohl-latex-width08">width=.8\textwidth</rendition>
         </tagsDecl>
      </encodingDesc>
      <revisionDesc>
         <change when="2015-11-25T17:22:00"
            who="https://github.com/peterstadler">Erste Korrekturen der Autoren eingearbeitet.</change>
         <change when="2015-11-25T14:04:00"
            who="https://github.com/peterstadler">Abbildungen überarbeitet.</change>
         <change when="2015-11-23T15:52:49.455+01:00"
                 who="https://github.com/peterstadler">Initial transformation from OxGarage TEI P5 to jTEI customization.</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div type="abstract" xml:id="bohl-abstract"><p>Der <soCalled>Digital Turn</soCalled> hat in den vergangenen Jahren zu einer kritischen Auseinandersetzung mit herkömmlichen Editionsprozessen im Kontext neuer Medien geführt. Im Bereich der Musikedition hat Joachim Veit den Übergang vom <soCalled>analogen</soCalled> zum digitalen Arbeiten maßgeblich mitgestaltet. Ausgehend von den in den zurückliegenden Jahren entstandenen methodischen und technologischen Grundlagen zeichnet sich nun ein bisher ausgebliebener Schritt digital vorliegender Musikeditionen in den musikalischen Alltag ab. Dieser Beitrag spannt den Bogen von den Anfängen bis hin zu innovativen Nutzungsmöglichkeiten digitaler Musikeditionen im Musikbetrieb von Morgen.</p></div>
      </front>
      <body>
         <div type="motto" xml:id="bohl-motto">
            <cit>
               <quote source="#bohl-ftn1">Disse Geschichte is lögenhaft to vertellen, Jungens, aver wahr is se doch, denn mien Grootvader, von den ick se hew, plegg jümmer, wenn he se mie vortüerde (mit Behaglichkeit vortrug), dabi to seggen <q>wahr mutt se doch sien, mien Söhn, anners kunn man se jo nich vertellen.</q> De Geschicht hett sick aber so todragen.</quote><ref type="bibl" target="#Grimm1977" xml:id="bohl-ftn1">S.&#8239;760</ref>
            </cit>
         </div>
         <div xml:id="bohl-div01">
            <head/>
            <p>Seit gut 14&#x00A0;Jahren beschäftigen sich am Musikwissenschaftlichen Seminar Detmold/Paderborn Wissenschaftler unter der Leitung von <name ref="#bohl-pers010">Joachim Veit</name> mit Ideen, Werkzeugen und Konzepten der digitalen Musikedition. Dies geschieht im Spannungsfeld zwischen traditioneller Editionswissenschaft, unter deren Maßstäben es sich doch um einen relativ kurzen Zeitabschnitt handelt, und der Informatik, die, von Grund auf wesentlich schnelllebiger, in diesem Zeitraum noch bedeutend Fahrt aufgenommen hat. 
               Dabei ist es ein zentrales Anliegen <name ref="#bohl-pers010">Veits</name>, <quote source="#bohl-ftn2">[…] Fach- und Technikwissen zusammenzubringen. Wir dürfen uns eben nicht durch die Technik unsere Möglichkeiten diktieren lassen &#x2013; und dies geschieht zum Beispiel da, wo eine Edition auf Auszeichnungsmöglichkeiten verzichten muß, bloß weil ein vom Verlag verwendetes Notationsprogramm dies nicht kann.</quote><ref xml:id="bohl-ftn2" n="2" target="#Veit2003-bohl" type="bibl">S.&#8239;231</ref> Dieses Beispiel ist exemplarisch für die Nebenläufigkeit von technischer Entwicklung und Editionswissenschaft, die es an gegenseitigem Austausch und Bezug mangeln lässt. Weder stehen dem Editor Werkzeuge für eine moderne/zeitgemäße (digitale) Editionsarbeit zur Verfügung, noch leben seine Arbeitsergebnisse über den engen traditionellen Anwendungskontext (Auflegen der Noten auf das Notenpult) hinaus oder wirken in die moderne Medienkultur hinein.</p>
            <p>Zum einen sind es die konkreten Implementierungen, z.&#8239;B. von Notensatzprogrammen, welche meist nicht für den Anwendungsfall der Musikedition und die mit ihm einhergehenden besonderen Erfordernisse gedacht waren. Zum anderen ist es die Musikedition, die sich nicht offensiv in den technischen Entwicklungsprozess einbringt, sich allenfalls als passiver Kunde denn als aktiver Motivator versteht. Hat sie es bislang nicht versäumt,</p>
            <p><quote source="#bohl-ftn3">[…] einen Blick auf die neuen Möglichkeiten zu werfen &#x2013; und zwar weniger unter dem Aspekt, was man alles machen kann, als unter dem Gesichtspunkt: Was erscheint von unserer Warte [jener des Editors] aus wünschenswert? Welche denkbaren Alternativen gibt es zur heutigen Editionsform? Was können uns dabei die neuen Techniken bringen? Was müssen <hi rend="italic">wir</hi> deshalb von <hi rend="italic">ihnen fordern</hi>?</quote><ref target="#Veit2003-bohl" type="bibl" xml:id="bohl-ftn3" n="3">S.&#8239;231</ref></p>
            <p>Damals noch an der Schwelle zum <hi rend="italic">Digital Turn</hi>, steht <name ref="#bohl-pers010">Veit</name> mit diesen Fragen exemplarisch für die erwachende Begierde der Editionswissenschaft, technische Neuerungen für die eigene Arbeit zu nutzen. Er rückt die Wichtigkeit eines entsprechenden Austauschs in den Fokus und weist gleichsam bereits darauf hin, dass sich die Editionsarbeit der Zukunft weiterentwickeln muss und wird. Sie ist mit neuen Fragestellungen konfrontiert, für die sie neue Werkzeuge benötigt. Auch der Nutzungskontext künftiger Editionen wird nicht auf das Notenpult beschränkt bleiben.</p>
            <p>Folgerichtig löst <name ref="#bohl-pers010">Veit</name> die Dichotomie <hi rend="italic">wir Editoren</hi> &#x2013; <hi rend="italic">ihr Entwickler</hi> in den folgenden Jahren zunehmend auf, wechselt selbst sogar insofern die Seite, als dass er heute, durch seine zahlreichen, im Kontext digitaler Edition arbeitenden Projekte, derjenige ist, von dem nun andere (Editoren) fordern. Dies mochte <name ref="#bohl-pers010">Veit</name> damals schwerlich erahnen, dennoch können seine Fragen als Keimzellen dieses Werdegangs und gleichsam als Forschungsagenda rund um das am Musikwissenschaftlichen Seminar Detmold/Paderborn geführte Projekt <hi rend="italic">Edirom</hi><note xml:id="bohl-ftn4" n="4">Vgl. <ref target="#Edirom2007" type="bibl"/></note> gelten.</p>
         </div>
         <div xml:id="bohl-div02">
            <head><name ref="#bohl-pers010">Veits</name> Fantasien 1 bis 5 </head>
            <p>Seiner eigenen Einladung folgend, Wünsche für technisch unterstützte, alternative Formen der Edition zu formulieren, kommt <name ref="#bohl-pers010">Veit</name> noch im selben Beitrag durch die <soCalled>Komposition</soCalled> seiner <hi rend="italic">Fantasien 1 bis 5</hi> nach. Mehr noch, er stellt seinen fünf <soCalled>Fantasien</soCalled> vier <soCalled>Bedenken</soCalled> und einen <soCalled>Einwand</soCalled> gegenüber, und weist gleichsam auf mögliche Probleme und Gefahren des <q>digitalen Umschwungs</q> hin. Betrachtet man die <hi rend="italic">Fantasien</hi> im Einzelnen, so kann man feststellen: Einiges ist bereits Realität geworden. Und zwar nicht durch <q>lautstarkes Fordern</q> von technischen Weiterentwicklungen,<note xml:id="bohl-ftn5" n="5">Vgl. <ref target="#Veit2003-bohl" type="bibl">S.&#8239;256</ref>.</note> sondern durch Projekte unter der Leitung von <name ref="#bohl-pers010">Veit</name>: </p>
            <list>
               <item>im Notentext einblendbare erläuternde Texte, welche die Ausschnitte varianter Quellen oder Parallelstellen mitliefern und erlauben, diese in eigenständigen Fenstern zu öffnen,<note xml:id="bohl-ftn6" n="6">Vgl. <ref target="#Veit2003-bohl" type="bibl" rend="ibid">S.&#8239;257</ref>.</note> 
               </item>
               <item>dynamische Lesartenverzeichnisse, die an das jeweilige Erkenntnisinteresse angepasst werden können.<note xml:id="bohl-ftn7" n="7">Vgl. <ref target="#Veit2003-bohl" type="bibl" rend="ibid">S.&#8239;260–261</ref>.</note>
               </item>
            </list>
            <p>Andere <hi rend="italic">Fantasien</hi> befinden sich in Detmold und der inzwischen etablierten Community der digitalen Musikedition in Bearbeitung, etwa </p>
            <list>
               <item>der konfigurierbare Notentext,<note xml:id="bohl-ftn8" n="8">Vgl. <ref target="#Veit2003-bohl" type="bibl" rend="ibid">S.&#8239;262</ref>. Vgl. Freischütz Digital, <hi rend="italic">CoreViewer</hi>, Detmold 2015, online abrufbar unter <ptr target="http://www.freischuetz-digital.de/FreiDi_CoreViewer/index.html"/></note>
               </item>
               <item>spezifische Abfrage- bzw. Adressiergrammatiken.<note xml:id="bohl-ftn9" n="9">Vgl. <ref target="#Veit2003-bohl" type="bibl" rend="ibid">S.&#8239;262</ref>. Dieses Problem wird z.&#8239;B. im Rahmen des Projekts Enhancing Music Notation Adressability (EMA) am Maryland Institute for Technology in the Humanities (MITH) angegangen. Vgl. dazu die Projektbeschreibung unter <ptr target="http://mith.umd.edu/research/project/enhancing-music-notation-addressability/"/> und Veröffentlichungen unter <ptr target="http://mith.us/ema/"/></note> 
               </item>
            </list>
            <p>Noch immer offen bleibt der Wunsch nach der Möglichkeit einer online verknüpften Betrachtung bestimmter Phänomene über Werkgrenzen hinweg.<note xml:id="bohl-ftn10" n="10">Vgl. <ref target="#Veit2003-bohl" type="bibl">S.&#8239;261</ref>.</note> Voraussetzung hierfür wäre, dass es die <q><hi rend="italic">Electronic-Complete-Editions-Collection</hi> von St. Utopia</q><ref target="#Veit2003-bohl" type="bibl" xml:id="bohl-ftn11" n="11" rend="ibid">S.&#8239;262</ref> bereits gäbe, fleißig befüllt durch die <q>Fachgruppe <hi rend="italic">Befreite Editionsinstitute</hi></q><ref target="#Veit2003-bohl" type="bibl" xml:id="bohl-ftn12" n="12" rend="ibid">S.&#8239;261</ref>, also die Digitalisierung des musikeditorischen Wissens bereits so weit fortgeschritten wäre, dass deren Inhalte auf der Basis von Ontologien semantisch verknüpft und somit ein Teil des <q>Semantic Web</q><note xml:id="bohl-ftn13" n="13">Vgl. <ref target="#Hitzler2008" type="bibl"/></note> wären.</p>
            <p>Diese <hi rend="italic">Fantasien</hi> waren jedoch nicht nur Motivation für Forschungs- und Entwicklungsprojekte, welche die digitale Musikedition in greifbare Nähe rücken lassen. Immer motiviert die nähere Beschäftigung mit solchen Fragestellungen und den dabei entstehenden Arbeitsergebnissen auch zu anderen Entwicklungen und neuen Forschungsansätzen, etwa durch die Integration von Klingendem zur Untersuchung und Illustration alternativer Stellen oder Interpretationen.<note xml:id="bohl-ftn14" n="14">Vgl. Freischütz Digital, Abschluss der Audio-Produktion am ETI der HfM Detmold, Detmold 2014, online abrufbar  unter <ptr target="http://freischuetz-digital.de/audio-production-2014.html"/> sowie: Freischütz Digital, <hi rend="italic">FreiDi:syncPlayer</hi>, Detmold 2015, online abrufbar  unter <ptr target="http://freischuetz-digital.de/demos/syncPlayer/test/syncPlayer.xhtml"/></note> Dies zeigt auf: die digitale Musikedition ist in ihren Facetten noch nicht ausdifferenziert, die Grenzen sind noch nicht gefunden. </p>
            <p>Abstrahiert man von den konkreten Forderungen und Umsetzungen der <hi rend="italic">Fantasien</hi> und betrachtet man die zunehmende Zahl an digital arbeitenden Musikeditionsprojekten, kann man durchaus davon sprechen, dass es heute nicht mehr primär um die Frage des Verhältnisses von Musikedition und neuen Medien geht. Vielmehr geht es darum, die digitale Musikedition zu einer wirklichen Alternative zur herkömmlichen papiergebundenen Edition musikalischer Werke zu machen, die mit eigenen Konzepten, etwa dem des interaktiven Notentextes, aufwarten kann. Auch die Förderpolitik hat in dieser Hinsicht klar Stellung bezogen: <quote source="#bohl-ftn15">Die Erschließung und/oder Digitalisierung von forschungsrelevanten objektbezogenen Sammlungen und die nachhaltige überregionale Bereitstellung der erzielten digitalen Daten ist ein dringendes Desiderat für die Forschung.</quote><ref xml:id="bohl-ftn15" n="15" target="#DFG_Standardbildung2013" type="bibl"/> Weiter hat sie die Relevanz digitaler Methoden und übergreifender Strukturen erkannt, insbesondere im Bereich der Editionswissenschaften,<note xml:id="bohl-ftn16" n="16">Vgl. <ref target="#Stock2015" type="bibl">S.&#8239;71</ref>.</note> und schreibt gezielt Programme für die interdisziplinäre Arbeit von Geisteswissenschaft und Informatik aus. Die digitale Edition <hi rend="italic">per se</hi> wird zwar noch nicht gefordert, aber die Frage, <hi rend="italic">ob</hi> digital gearbeitet werden soll, ist zugunsten der Frage, <hi rend="italic">wie</hi> digital gearbeitet werden soll, in den Hintergrund getreten. Doch was unterscheidet den digitalen Prozess der Musikedition eigentlich vom herkömmlichen Vorgehen?</p>
         </div>
         <div xml:id="bohl-div03">
            <head>Digitale Musikedition … und was dann?</head>
            <p>Der Arbeitsprozess einer digitalen Musikedition ist nicht unähnlich dem der traditionell <soCalled>analogen</soCalled> Editionsarbeit. Unterschiede liegen vor allem in der Art und Menge der in die Editionsarbeit einbezogenen Quellenmaterialien, in der Unterstützung der Arbeitsschritte durch (Software-)Werkzeuge und der konzeptionellen Beschaffenheit der Arbeitsergebnisse.</p>
            <p>Ausgangspunkt ist immer eine umfassende Recherche zur Quellenlage des zu edierenden Werkes. Diese kann dank der zunehmend in digitalen Katalogen erfassten Bibliotheksbestände in weiten Stücken online erfolgen. Ein hervorhebenswertes Beispiel dafür ist die Online-Publikation des <hi rend="italic">Répertoire International des Sources Musicales</hi>. Die Schwerpunkte der 1.010.000 Nachweise bilden <q>[…] geschätzt etwa 1/3 sämtlicher weltweit überlieferter Musikhandschriften bis 1800</q> ab, sowie <q>etwa 60&#8239;% sämtlicher weltweit überlieferter Musik-Drucke bis&#x00A0;1800</q>.<note xml:id="bohl-ftn17" n="17">RISM – Répertoire International des Sources Musicales. (Internationales Quellenlexikon der Musik &#x2013; International Inventory of musical sources), URL: <ptr target="https://opac.rism.info"/></note> Je nach Werk reihen sich neben den Notentexten auch Texte, Abbildungen und ggf. Audio- und Videomaterialien ein &#x2013; ein typisches Beispiel für die ausgeprägte Multimodalität digitaler Quellen.</p>
            <p>Neben der Quellenrecherche gilt es im <soCalled>analogen</soCalled> zunächst, Editionsrichtlinien zu formulieren, die neben Grundsätzlichem zur Bewertung und Erfassung der berücksichtigten Quellen auch den Umgang mit dem musikalischen Inhalt der Quellen regeln. Dies betrifft insbesondere auch Transkriptionsrichtlinien, die sowohl die zu berücksichtigenden Phänomene der Quellen regeln, als auch deren Darstellung im edierten Text. </p>
            <p>Die digitale Musikedition setzt derweil die Festlegung einer Syntax zur Codierung voraus, die den editorischen Ansprüchen gerecht wird. So haben sich in musikeditorischen Projekten inzwischen die Codierungsrichtlinien der <hi rend="italic">Music Encoding Initiative</hi> (MEI) und das damit verbundene gleichnamige XML-Format etabliert, um der durch den <hi rend="italic">Digital Turn</hi> hervorgebrachten Forderung nach einer Bereitstellung von Forschungsdaten zur Nachnutzung nachzukommen. Ihr <soCalled>digitales</soCalled> Pendant finden Editions- und Transkriptionsrichtlinien in den MEI-Schemadefinitionen.<note xml:id="bohl-ftn18" n="18">Vgl. <ref target="#MEI_2-1-1" type="bibl"/> sowie die zugehörigen XML-Schemata: MEI 2013 v2.1.1, 2014, URL: <ptr target="https://github.com/music-encoding/music-encoding/releases"/></note>
            </p>
            <p>Die anschließende Filiation, Textkritik, Emendation sowie die Herstellung der finalen Reinschrift erfolgen wie gehabt. Diese erfahren durch die Verlagerung in das digitale Medium, etwa mit der Unterstützung durch Software-Werkzeuge, auch punktuelle Ergänzungen durch <q>rein digitale</q> Arbeitsschritte, so etwa bei der Aufbereitung der Quellen, wenn deren digitale Faksimiles zunächst eingepflegt und entsprechend den Editionsrichtlinien kartographiert werden. Beispielsweise werden Faksimiles im Arbeitsschritt der <hi rend="italic" xml:space="preserve">Vertaktung </hi>um Verlinkungen angereichert, die eine Verbindung zwischen digitalen Bildausschnitten mit der logischen Codierung der abgebildeten Musik ermöglichen. Nach der Aufbereitung mehrerer Quellen ermöglicht dies später etwa synchrones taktgenaues Navigieren durch deren digitale Faksimiles. Bei Auswahl eines Taktes in einer Quelle werden dann automatisch die Parallelstellen in allen anderen betrachteten Quellen angesteuert.<note xml:id="bohl-ftn19" n="19">Vgl. die in <hi rend="italic">Edirom</hi> erstellten digitalen Musikeditionen. Die entsprechenden Werkzeuge und weiterführende Informationen sind online verfügbar unter <ptr target="http://www.edirom.de"/> bzw. <ptr target="https://github.com/Edirom"/></note>
            </p>
            <p>Im Vergleich dazu erfordert die <soCalled>analoge</soCalled> Editionsarbeit ein mediales Multitasking; man kann originale Quellen nur bedingt als Arbeitsmaterialien verwenden, die Arbeit passiert an unterschiedlichen Stellen gleichzeitig, die handschriftliche Bewertung und Annotierung der Faksimilekopien, die Erstellung des kritischen Berichts am Computer, etc. Eine wesentliche Neuerung durch die digitale Arbeitsweise ist die medienbruchfreie Integration aller editorischen Erkenntnisse und Entscheidungen in einer Codierung, die alle Aspekte der editorischen Arbeit fassen kann.</p>
            <p>Damit gewonnen ist eine Flexibilisierung der Arbeitsergebnisse. Das Ziel einer digitalen Musikedition ist nicht zwangsläufig die <hi rend="italic">eine</hi> (gedruckte) Notenausgabe samt kritischem Bericht. Vielmehr sind es die ihr zu Grunde liegenden Daten, aus denen sich dynamisch ganz verschiedene, dem jeweiligen Erkenntnisinteresse angepasste Notensätze generieren lassen. Dirigierpartitur, Studienpartitur und Einzelstimmen sind letztlich nur noch verschiedene Renderings der gleichen Daten mittels unterschiedlicher Stylesheets, zwischen denen umzuschalten mit wenigen Mausklicks erreicht ist. Diese von ihrer äußerlichen Erscheinungsform losgelösten und auf ihren tatsächlichen Informationsgehalt konzentrierten Daten sind gewissermaßen der Kern einer digitalen Musikedition, bereits in ihrer Rohform stellen sie eine unschätzbare Grundlage für darauf aufbauende Forschungsarbeiten dar. Hier sei als Beispiel die Computer-gestützte Analyse großer Musikdatensätze genannt, ihre umfassende und ganzheitliche Betrachtung, die zu neuen Einsichten über Stil und Schaffen eines Komponisten oder einer ganzen Epoche beitragen kann. Diese Flexibilisierung der editorischen Arbeitsergebnisse ebnet folglich den Weg für eine möglichst vielseitige Nutzbarmachung für Wissenschaft und Praxis gleichermaßen &#x2013; eine Bedingung, die <name ref="#bohl-pers011">Kepper</name> mit Blick auf Aufwand und Kosten dieser Arbeit zu Recht fordert.<note xml:id="bohl-ftn20" n="20">Vgl. <ref target="#Kepper2011" type="bibl">S.&#8239;184</ref>.</note>
            </p>
            <p>Der kritische Bericht muss derweil nicht der reinen Textform verhaftet bleiben. In den digitalen Medien sind zahlreiche Kontextualisierungstechniken bekannt. Das Ziel einer adäquaten Präsentation verschiedener aufeinander bezogener Medieninhalte ist die Minimierung des Lese- und Assoziationsabstandes. Ein Beispiel aus dem Projekt <hi rend="italic">Edirom</hi> ist die synchronisierte Anzeige mehrerer Faksimiles und des edierten Notentextes samt eingeblendeter Symbole zur Darstellung der an den jeweiligen Stellen relevanten editorischen Anmerkungen. Alternativ lässt sich der Zugang über den kritischen Bericht nehmen. Die Darstellung einer Einzelanmerkung beinhaltet nicht nur die relevanten Quellenausschnitte, sie erlaubt es auch alle betroffenen Quellen an der relevanten Stelle in eigenständigen Fenstern zu öffnen. Dies macht die <hi rend="italic">Edirom</hi>-Projektdateien zu einer überaus mächtigen Form der Präsentation kritischer Berichte. Schon Anfang des 20.&#8239;Jahrhunderts, genauer 1908, tauchen erste Forderungen nach einer gesamtheitlichen Publikation einschließlich aller Quellen auf,<ref target="#Friedlaender1907" type="bibl" xml:id="bohl-ftn21" n="21">S.&#8239;18</ref> um die Arbeit des Editors transparenter zu machen. Im Rahmen <hi rend="italic">digitaler</hi> Musikeditionen ist dies erstmals auch realisierbar.</p>
            <p>Techniken der Bildannotation<note xml:id="bohl-ftn22" n="22">Siehe z.&#8239;B. <ref target="#Goetzelmann2008" type="bibl"/>.</note> können in diesem Zusammenhang entscheidend zu einer größeren Transparenz der Edition beitragen. So können Passagen des kritischen Berichts &#x2013; ähnlich Sprechblasen &#x2013; direkt an den betreffenden Stellen im edierten Text verankert sein. Eine wünschenswerte Bereicherung ist ferner die Ergänzung um audiovisuelle Medieninhalte.<note xml:id="bohl-ftn23" n="23">Vgl. <ref target="#Schloots2015" type="bibl">S.&#8239;45</ref>.</note> Klangbeispiele können verschiedene, im Editionsprozess diskutierte Varianten gegenüberstellen, die editorischen Absichten hörbar machen und Musikern wie Musikenthusiasten als Erarbeitungshilfe dienen. Gerade historisch informierte Aufführungspraktiken erschließen sich in einer textuellen Beschreibung oft nur schwer, werden am klingenden Beispiel aber direkt nachvollziehbar. Dabei müssen solche Klangbeispiele nicht nur aufwendige Spezialproduktionen sein, wie im Falle des Projektes <hi rend="italic">Freischütz Digital</hi>.<note xml:id="bohl-ftn24" n="24">Vgl. <ref target="#FreiDi2013" type="bibl"/> sowie: <ref target="#FreiDi2014" type="bibl"/></note> Ab dem späten 19.&#8239;Jahrhundert existieren Tonaufzeichnungen, die den Hörer an so mancher historischer Aufführung partizipieren lassen. Ab den 1980er Jahren entwickelt sich auch die Möglichkeit, Aufführungsstile zunehmend detaillierter am Computer zu simulieren und damit dem geneigten Produzenten die volle Kontrolle über jede feinste Nuance zu geben.<note xml:id="bohl-ftn25" n="25">Vgl. <ref target="#Berndt2015" type="bibl"/>. Sowie: <ref target="#Haehnel2013" type="bibl"/>.</note> Schließlich können auch Bild- und Videomaterialien den kritischen Bericht begleiten, was beispielsweise bei bildlichen Darstellungen heute nicht mehr existierender historischer Instrumente bereits praktiziert wird.<note xml:id="bohl-ftn26" n="26">Vgl. <ref target="#Posch1999" type="bibl"/></note>
            </p>
            <p>Die Präsentation eines solchen multimedialen Datensatzes stellt aber für die Benutzerführung eine große Herausforderung dar. </p>
            <p><quote source="#bohl-ftn27">Während gedruckte Ausgaben aufgrund der üblichen Lesegewohnheiten eine gewisse logische Abfolge des Textes anhand der Seitenzahl implizieren, sieht sich der Benutzer einer digitalen Ausgabe einem <soCalled>mehrdimensionalen Raum</soCalled> gegenüber, der durch zahllose Verweise dutzende von Erschließungswegen erlaubt.</quote><ref target="#Kepper2011" type="bibl" xml:id="bohl-ftn27" n="27">S.&#8239;213</ref></p>
            <p>Die in der Informatik beheimateten Forschungsfelder der Mensch-Computer-Interaktion und Informationsvisualisierung sind der Lösung genau solcher Probleme gewidmet. Für sie kann die digitale Musikedition ein ebenso anspruchsvolles wie facettenreiches Anwendungsszenarium darstellen. Als eine von wenigen Institutionen hat das in Detmold ansässige <hi rend="italic">Zentrum für Musik- und Filminformatik</hi> (ZeMFI) seine Forschungs- und Entwicklungstätigkeiten unter anderem in eben diesem Feld angesiedelt. Die Autoren beschäftigen sich in ihrer Arbeit unter anderem mit Fragen zu technologischen Interaktionsmöglichkeiten von Musikern und Tontechnikern und der technisch gestützten Aneignung und Kontrolle von Musik und Klang. Ein wesentlicher Anknüpfungspunkt ist dabei auch die Frage: Welche über den editorischen Kontext hinausgehenden Möglichkeiten bietet das digitale Notenmedium etwa für den künstlerischen Bereich oder die Musikproduktion? Zum einen bestehen natürlich weiterhin die traditionellen Anwendungsszenarien digitaler Musikeditionen, die jedoch durch die technischen Möglichkeiten eine Erweiterung erfahren können:</p>
            <list>
               <item>Sie dienen den ausführenden Musikern als Notenmaterial, das dank flexiblem Notensatz an die jeweiligen Erfordernisse und durch die Auswahl varianter Stellen angepasst sowie um Einzeichnungen ergänzt werden kann.</item>
               <item>Sie dienen als Materialien zur musikwissenschaftlichen Recherche und praktischen Erarbeitung von Interpretationen. Dabei können gezielt historische und ahistorische Fassungen erstellt und verglichen werden.</item>
               <item>Digitale Notenständer sind mehr als nur Anzeigegeräte. Wie jedes Tablet sind sie vollwertige leistungsstarke Computer mit Touch- und Stifteingabe, die sich auch miteinander vernetzen lassen. So eröffnet sich ein neuer Kanal zum Informationsaustausch zwischen den Musikern eines Ensembles. Diese müssen nicht einmal mehr im gleichen Raum zusammen sitzen, sondern können über die Welt verteilt arbeiten. Dieser Informationskanal kann Komponenten sozialer Netzwerke implementieren, die es etwa Musikstudenten erlauben, sich bei der Erarbeitung von Stücken auszutauschen.</item>
               <item>Musikeditionen dienen immer auch als praktisches Arbeitsmaterial der Tonmeister in der Musikproduktion. Gerade hier werden sie mit zahlreichen Einzeichnungen angereichert, deren Bedeutung digital erfasst und interpretiert werden können. Diese Interpretationen erleichtern spätere Aufgaben im musikalischen Schnittprozess.</item>
            </list>
            <p>Zum anderen werden in Zukunft auch Nutzungskontexte relevanter, die aus bisheriger Sicht noch unkonventionell erscheinen mögen. Hier seien nur einige Beispiele kurz genannt:</p>
            <list>
               <item>Das Gebiet des <hi rend="italic">Music Information Retrieval</hi> eröffnet der Musikwissenschaft Werkzeuge zur Analyse großer Musikdatensätze, die sich auf manuellem Wege nur schwer in vergleichbarer Tiefe erschließen lassen. Die Daten einer digitalen Musikedition sind hinsichtlich ihrer Prozessierbarkeit auf musikimmanente Fragestellungen (z.&#8239;B. harmonische Analysen) hin den Audiodaten und Notenscans deutlich überlegen.</item>
               <item>Die Vielzahl an möglichen Erschließungspfaden einer digitalen Musikedition begünstigt auch ihre Nutzung in einem pädagogischen Kontext, d.&#8239;h. zur Musikvermittlung/-lehre, sowie in entsprechend aufbereiteter Form als interaktive Ausstellungsinstallationen.</item>
               <item>Für die Interpretationsforschung eröffnen digitale Musikeditionen Einblicke in historische Interpretationspraktiken und ihre Wandlungsprozesse. Gleiches gilt für kompositorische Stile, Stilepochen und ihre Entwicklung.</item>
               <item>Zeitgenössische Künstler verarbeiten nicht selten historisches Material in ihren Werken. Die Polystilistik<note xml:id="bohl-ftn28" n="28">Vgl. <ref target="#Denhoff1988" type="bibl"/>. Sowie: <ref target="#Dickinson1989" type="bibl"/>.</note> wird in der heutigen Musikkultur rege praktiziert, ist auch in der Vertonung von Filmen und interaktiven Medien<ref target="#Berndt2011" type="bibl" xml:id="bohl-ftn29" n="29"/> (z.&#8239;B. Videospielen) oft anzutreffen, wo gezielt mit den assoziativen Ladungen bestimmter Stile und Stilmittel gearbeitet wird. Digitale Musikeditionen vereinfachen den Zugang und die Erschließung solcher Werke. Mehr noch, die Daten einer digitalen Edition können direkt als Material zur Computer-basierten Musikproduktion verwendet werden oder als Eingabe eines stilimitierenden generativen Kompositionsverfahrens<ref target="#Cope1996" type="bibl" xml:id="bohl-ftn30" n="30"/> dienen.</item>
            </list>
            <p>Im Folgenden soll an zwei Beispielen, dem digitalen Notenständer und der Musikproduktion, detaillierter illustriert werden, inwiefern die Forschung inzwischen über die digitale Edition an sich hinaus geht und den Kontext ihrer potentiellen Nutzung miteinschließt.</p>
         </div>
         <div xml:id="bohl-div04">
            <head>Räumlich verteilte Ensembles</head>
            <p>Der digitale Notenständer als Wiedergabemedium einer Musikedition ist nicht darauf beschränkt, diese nur anzuzeigen, sondern bietet auch neue Wege der künstlerischen Nutzung. Eine Möglichkeit ist die Unterstützung räumlich verteilter Ensembles. Hierbei stehen die Musiker nicht in gewohnter Aufstellung kompakt beieinander, sondern sind weit voneinander entfernt. Bereits in Renaissance und Barock wurde die Räumlichkeit der Musik explizit gestaltet. Als Meister der Mehrchörigkeit gilt etwa <name ref="#bohl-pers005">Giovanni Gabrieli</name> (1557&#x2013;1612), der seine Musikergruppen auf den verschiedenen Emporen des Markusdoms zu Venedig positionierte.<note xml:id="bohl-ftn31" n="31">Vgl. <ref target="#Gabrieli1597" type="bibl"/></note> Auch im weiteren Verlauf der Musikgeschichte wurden solch räumliche Konzepte immer wieder künstlerisch erforscht, u.&#8239;a. von <name ref="#bohl-pers001">Berlioz</name> (1803&#x2013;1869) in seiner <title ref="#bohl-work001">Symphonie fantastique</title>,<note xml:id="bohl-ftn32" n="32"><name ref="#bohl-pers001">Hector Berlioz</name>, <title ref="#bohl-work001">Symphonie fantastique &#x2013; Épisode de la vie d’un artiste</title> (op.&#8239;14), Paris 1830.</note> bei der ein Oboist spielend den Konzertsaal von außen betritt, bis hin zur heute in der elektroakustischen Musik allgegenwärtigen künstlichen Räumlichkeit durch Spatialisierung,<ref target="#Barrett2007" type="bibl" xml:id="bohl-ftn33" n="33"/> deren Ursprünge bereits bei Varèse zu finden sind:</p>
            <p><quote source="#bohl-ftn34">Die räumliche Entfaltung des organisierten Schalls, z.&#8239;B. durch 425&#x00A0;Lautsprecher wie beim <soCalled>Poeme electronique</soCalled> von&#x00A0;1958, bildete eine der frühesten Vorstellungen Varèses […]. Zur Freiheit des Klanges gehört also offensichtlich auf strukturelle Weise auch der freie offene Raum.</quote><ref target="#Weibel1987" type="bibl" xml:id="bohl-ftn34"/></p>
            <p>Das räumlich verteilte Musizieren bringt verschiedene Probleme für die Musizierenden mit sich. Erstens hören sich die Musizierenden undeutlich, etwa aufgrund der Tatsache, dass die Akustik des Raumes nun deutlich zwischen die Musiker tritt. Zudem überdeckt das eigene Instrument oftmals den Klang anderer Instrumente, insbesondere der entfernteren. Zweitens hören sich die Musizierenden zeitverzögert. Bei einer Luftschallgeschwindigkeit von 343&#8239;m/s benötigt der Schall, um einen Meter zurückzulegen, ca.&#8239;2,9&#8239;ms. Es ist aber bekannt, dass Musiker bei hohen Latenzen zunehmende Schwierigkeiten beim Zusammenspiel haben. So zeigte eine Studie von <name ref="#bohl-pers002">Chafe</name> und <name ref="#bohl-pers006">Gurevich</name>,<ref target="#Chafe2004" type="bibl" xml:id="bohl-ftn35" n="35"/> bei der Duos mit variablen Verzögerungen einfache Rhythmen miteinander spielten, dass sich bereits ab einer Zeitverzögerung von 14&#8239;ms bei der Mehrzahl der Duos das Tempo verlangsamt. Bei Experimenten von <name ref="#bohl-pers003">Chew</name> et al.,<ref target="#Chew2004" type="bibl" xml:id="bohl-ftn36" n="36"/> die im Gegensatz zur vorgenannten Studie mit professionellen Musikern ausgeführt wurden, nannten die Musizierenden eine Zeitverzögerung von 50&#8239;ms als Grenze, bei der ein Zusammenspiel gerade noch möglich sei. Dies entspricht einer Entfernung von ca.&#8239;17&#8239;m. </p></div>
            <div xml:id="h.fhllf53m05a4">
               <head>Fallstudie</head>
               <p>Als ebenso anschauliches wie typisches Beispiel für eine Aufführung mit räumlich verteiltem Ensemble soll ein Auftritt des Blockflötenduos <hi rend="italic">TWiNS</hi> in der Kunstakademie Münster im Juni&#x00A0;2015 die nachfolgenden Ausführungen illustrieren.</p>
               <figure xml:id="bohl-fig01" place="here">
                  <graphic url="figures/bohl-fig01.pdf" width="2530px" height="1482px"/>
                  <head type="legend">Die Verteilung des Ensembles <hi rend="italic">TWiNS</hi> bei einem Auftritt in der Kunstakademie Münster im Juni&#x00A0;2015</head>
               </figure>
               <p>Aufgeführt wurde der dritte Satz <q>Four tulips, two for you</q> der Komposition <title ref="#bohl-work002">TWINS</title> von <name ref="#bohl-pers009">Matthias Maute</name>,<note xml:id="bohl-ftn37" n="37"><name ref="#bohl-pers009">Matthias Maute</name>, <title ref="#bohl-work002">TWINS</title>, Münster 2015.</note> ein Stück, bei dem eine exakte Synchronisierung der Musiker aufgrund des hohen Tempos und des rhythmischen Charakters essentiell ist. Während das Publikum an einer zentralen Stelle positioniert war, die eine ausgewogene Wahrnehmung beider, aus unterschiedlichen Richtungen erklingenden Musiker erlaubte, waren die Bedingungen für die Musiker aus folgenden Gründen ungünstig: </p>
               <pb/>
               <list>
                  <item>Da sich die zwei Musiker an völlig unterschiedlichen Positionen auf zwei verschiedenen Etagen befanden (vgl. Abb.&#x00A0;<ref target="#bohl-fig01" type="crossref" rend="no"/>), hatten sie keinen Sichtkontakt zur gegenseitigen Koordination. </item>
                  <item>Aufgrund der Distanz konnten sie sich für ein synchronisiertes Spiel weder klanglich, noch hinsichtlich des Timings ausreichend deutlich hören. Gepaart mit der akustischen Maskierung der anderen Blockflöte durch den Klang des eigenen Instruments (beides Bassflöten) wird eine Orientierung am Spiel des jeweils anderen Musikers unmöglich. </item>
               </list>
               <p>Der damit einhergehende Verlust sämtlicher Orientierungs- und Kommunikationsmöglichkeiten der Musiker untereinander kann als <q>worst case</q> hinsichtlich des synchronisierten Spiels angesehen werden. Für Szenarien dieser Art wurde am <hi rend="italic">ZeMFI</hi> eine Lösung erarbeitet, die den gesamten Prozess von der Vorbereitung der Materialien, dem Üben, dem Proben bis zum Konzertieren unterstützt. </p>
               <p>Während das verteilte Musizieren traditionell durch den Blickkontakt des gesamten Ensembles zum Dirigenten das synchrone Musizieren ermöglicht, kann dies bei komplexeren Verteilungen &#x2013; wie in diesem konkreten Fall &#x2013; nicht mehr vorausgesetzt werden. Zur Abhilfe können heute Click-Tracks genutzt werden. Hierbei handelt es sich um nichts anderes als das Ticken eines Metronoms, wobei Taktart- und Tempoänderungen bei deren Erstellung gleich mit berücksichtigt werden können. Die Clicks können den Musikern dann etwa mittels Funkkopfhörern zugespielt werden und ermöglichen somit eine zeitliche Orientierung auch ohne Sichtkontakt. Ein Nachteil der Click-Tracks im Zusammenhang mit räumlich verteilten Ensembles ist, dass es den Musikern schwerfällt sich am Spiel des anderen zu orientieren. Wenn ein Musiker die Synchronität zu den anderen Spielern verliert, fällt es mitunter schwer dies zu bemerken. Eine Lösung hierfür ist es, zu Beginn von neuen Abschnitten einen charakteristischen Sound, ein sogenanntes Earcon,<note xml:id="bohl-ftn38" n="38">Vgl. <ref target="#Blattner1989" type="bibl"/>.
                  </note> abzuspielen oder kurze Ansagen in den Click-Track zu integrieren. Angenehmer für die Musiker ist es jedoch, die aktuelle Position visuell zu veranschaulichen.</p>
               <p>Im Kontext der am <hi rend="italic">ZeMFI</hi> vorgenommenen Überlegungen zum Einsatz digitaler Musikeditionen lag es nahe, auch die Möglichkeiten digitaler Notenständer in die Problemlösung zu integrieren. Die Idee war es, ein digitales Notenpult um eine neue Funktionalität zu erweitern. Gleichzeitig zur Anzeige der Partitur sollte der Puls der Musik auf dem Notenbild animiert und ein Click-Track auf den Kopfhörern abgespielt werden. Im Vergleich zu einer reinen Click-Track-Lösung erleichtert die visuelle Anzeige die Orientierung in einer möglicherweise komplexen Partitur. Wenn jeder Musiker einen digitalen Notenständer vor sich stehen hat, besteht noch das technische Problem der exakten Synchronisierung dieser Notenständer.</p>
               <p>Um die Anforderungen für ein solches System besser zu identifizieren, wurde eine PACT-Analyse durchgeführt. PACT steht dabei für <q>People, Activities, Context, Technologies</q>.<note xml:id="bohl-ftn39" n="39">Vgl. <ref target="#Benyon2010" type="bibl"/>.</note> Dabei werden die handelnden Personen charakterisiert, sowie die Aktivitäten, die sie mit dem System ausführen wollen, der Kontext in dem diese Aktivitäten ausgeführt werden und die Technologien, die zur Realisierung genutzt werden können.</p>
               <p>In unserem Fall sind die beteiligten Personen ausführende Musiker/innen, Komponistinnen und Komponisten, Ensembleleiter/innen sowie Tontechniker/innen, die im Kontext der folgenden essentiellen Aktivitäten jeweils unterschiedliche Rollen ausfüllen:</p>
               <list>
                  <item>
                     <hi rend="bold">Vorbereiten:</hi> Um den Click-Track zu erstellen, muss der Komponist oder der Tontechniker Angaben zu Takt und Metrum in ein entsprechendes System einpflegen. Bei metrisch komplexen Stücken müssen Takt- und Tempowechsel berücksichtigt werden. Ebenfalls ist es nötig, graduelle Tempowechsel (A<hi rend="italic">ccelerando</hi> oder <hi rend="italic">Ritardando</hi>) zu unterstützen. Die Angaben sind später die Grundlage des erstellten Click-Tracks. Zudem muss die Partitur als graphisches Format bereitgestellt werden, entweder als graphischer Export eines Noteneditors oder als Scan einer Partitur. Falls ein Zuspiel des Click-Tracks über eine Beschallungsanlage gewünscht ist, muss diese ebenfalls bereitgestellt werden. Die Aktivität <q>Vorbereiten</q> wird nur relativ selten ausgeführt. Solche Aktivitäten sollen leicht zu erlernen sein oder man sollte sich leicht an diese erinnern können.<note xml:id="bohl-ftn40" n="40">Vgl. <ref target="#Benyon2010" type="bibl"/></note>
                  </item>
                  <item>
                     <hi rend="bold">Üben:</hi> Diese Aktivität führt jeder Musiker für sich aus. Ab einem gewissen Grad der Beherrschung werden die Musiker das Stück mit Click-Track üben wollen. Das System sollte es ermöglichen, einzelne Abschnitte oder auch das ganze Stück in einem langsameren Tempo zu spielen. Zudem müssen die Benutzer in einem beliebigen Takt beginnen können.</item>
                  <item>
                     <hi rend="bold">Proben:</hi> Wenn die Musiker gemeinsam proben, muss es schnell möglich sein, einen Durchlauf zu unterbrechen und an beliebigen Stellen wieder zu beginnen. Dies sollte vom Ensembleleiter, dem Komponisten, dem Tontechniker oder einem Mitglied des Ensembles zentral gesteuert werden können. Ebenfalls sollte es möglich sein, das Tempo eines Abschnitts oder des gesamten Stückes zu verändern. Die Aktivität <q>Proben</q> ist bei professionellen Ensembles in der Regel von hohem Zeitdruck geprägt. Die Interaktion mit dem System muss daher sehr zeiteffizient sein.</item>
                  <item>
                     <hi rend="bold">Konzertieren:</hi> Die Musiker werden mit Hilfe des Systems synchronisiert. Zusätzlich wird falls nötig das Zuspiel auf der Beschallungsanlage ausgegeben. Das System wird von einem der Beteiligten gestartet und läuft dann ohne weiteren Eingriff durch.</item>
               </list>
               <p>Der soziale Kontext unterscheidet sich in den verschiedenen Aktivitäten. Die Nutzer sind bei den Aktivitäten <q>Vorbereiten</q> und <q>Üben</q> in der Regel auf sich allein gestellt. Bei Proben und Konzert können die Beteiligten bei der Nutzung auf die Hilfe der Gruppe zählen. Bei Proben wird die Leitung oftmals durch den Komponisten oder Ensembleleiter übernommen. Aber auch der physische Kontext spielt eine Rolle: Die digitalen Notenständer müssen synchronisiert werden. Je nach Situation kann dazu auf unterschiedliche Technologien zurückgegriffen werden. Da gerade die physische Nähe überwunden werden soll, kann auch die dauerhafte physische Kopplung der Geräte zum Zwecke der Synchronisation nicht vorausgesetzt werden. Der Rückgriff auf Funksignale ist hier zu empfehlen. Im Freien (und oftmals auch in Konzertsälen und Kirchen) steht jedoch in der Regel kein WLAN zur Verfügung. Daher sollte die Lösung nicht ein bereits bestehendes Funknetzwerk zur Synchronisierung der digitalen Notenständer voraussetzen. </p>
               <p>Potentiell geeignete Technologien sind Tablets und Laptops. Tablets haben den Vorteil, dass sie leichter auf Orchesternotenpulten Platz finden. Sie eignen sich ideal als passive Displays für die Musiker. Laptops werden hingegen aufgrund ihrer besseren Eingabemöglichkeiten für aktive Tätigkeiten besser geeignet sein, insbesondere für die Aktivität <q>Vorbereiten</q>.</p>
            </div>
            <div xml:id="h.yc9cgf5jdezk">
               <head>Umsetzung</head>
               <p>Auf der Basis der oben beschriebenen Fallstudie und PACT-Analyse wurden zwei Anwendungen entwickelt, die das synchronisierte Musizieren per Laptop/Tablet unterstützen. <hi rend="italic">WebMaestro</hi><note xml:id="bohl-ftn41" n="41">Zentrum für Musik- und Filminformatik der Hochschule für Musik Detmold und der Hochschule OWL und Earquake, Epizentrum für experimentelle Musik der Hochschule für Musik Detmold, <hi rend="italic">WebMaestro</hi>, Detmold 2014, online abrufbar unter <ptr target="http://www.zemfi.de/wp-content/uploads/2015/07/WebMaestro13.html"/></note> (siehe Abb.&#x00A0;<ref target="#bohl-fig02" type="crossref" rend="no"/>) unterstützt die Musiker/innen bei den Aktivitäten <hi rend="italic">Vorbereiten</hi>, <hi rend="italic">Üben</hi> und <hi rend="italic">Proben</hi>. Eine spezielle App für Tablets <hi rend="italic">sam</hi> (synchronized app maestro) unterstützt die Musiker bei <hi rend="italic">Proben</hi> und im <hi rend="italic">Konzert</hi> (siehe Abb.&#x00A0;<ref target="#bohl-fig04" type="crossref" rend="no"/>).</p>
               <figure xml:id="bohl-fig02">
                  <graphic url="figures/bohl-fig02a.png" width="1188px" height="1345px"/>
                  <head type="legend"/>
               </figure>
               <figure xml:id="bohl-fig02b">
                  <graphic url="figures/bohl-fig02b.png" width="1188px" height="1560px"/>
                  <head type="legend"><hi rend="italic">WebMaestro</hi>: Es folgt eine Kurzbeschreibung der Interface-Elemente: (1) Laden gespeicherter Stücke, (2) Angabe von Titel und Komponist/in, (3) kurze Beschreibung der Funktionalität, (4) Eintragen der Abschnitte mit Taktart und Tempo, (5) hörbare Signalen, (6) gesprochene Anweisungen, (7) Verknüpfung mit der grafischen Partitur, (8 und 9) Speichern, (10) Abspielen</head>
               </figure>
               <!--<note resp="Benjamin_Bohl">
                     <date when="2015-11-23T22:20:00Z"/>hier ggf. Rücksprache bzgl der Abbildung und der Umsetzung im Druck</note>-->
               <p>
                  <hi rend="italic">WebMaestro</hi> ist ein web-basierter Click-Track-Generator und -Player. Im Grunde dient <hi rend="italic">WebMaestro</hi> der Vorbereitung der Daten. Die Einrichtung des Click-Tracks bis zur finalen Fassung mit den gewünschten Tempobereichen und -kurven, sowie gesprochenen Anweisungen bedürfen ggf. mehrerer Eingriffe und Korrekturen, die sich erst aus dem Übe- und Probekontext ergeben. Aus diesem Grund ist das Werkzeug so angelegt, dass es ohne Zwischenschritte für diese drei Aktivitäten genutzt werden kann. Selbstverständlich kann diese Anwendung auch im Konzerteinsatz Verwendung finden, sofern die Zuspielung von Click-Tracks genügt.</p>
               <p>Nutzt man zusätzlich Laptops oder Tablets als digitale Notenständer und möchte man auf diesen eine synchronisierte Wiedergabe der Stimmenauszüge der Musiker ermöglichen, erübrigt sich die Verteilung des Click-Tracks per Funk, da die Tablets bzw. Laptops den Click-Track synchronisiert abspielen können. Konfrontiert mit dem Grundproblem, dass Uhren in Computersystemen nicht perfekt arbeiten (siehe Abb.&#x00A0;<ref target="#bohl-fig03" type="crossref" rend="no"/>) wurden unterschiedliche Methoden zur Synchronisation in Erwägung gezogen. Zwei Uhren können nämlich sowohl voneinander um einen konstanten Wert abweichen (<hi rend="italic">clock offset</hi>) als auch unterschiedlich schnell laufen (<hi rend="italic">clock drift</hi>). Untersucht wurde <pb/>die Synchronisierung über Network Time Protocol (NTP), radiobasierte Zeitzeichen (DCF77) und Global Positioning System (GPS).<ref target="#Hadjakos2015" type="bibl" xml:id="bohl-ftn42" n="42"/> Die besten Ergebnisse lieferte aber ein selbstgebauter <q>verteilter Knopf</q>, der <hi rend="italic">Distributed Button</hi>, der zeitgleich an alle angeschlossenen Geräte ein Signal sendet, was dazu genutzt wird, das konstante <hi rend="italic">offset</hi> zwischen den Uhren auszugleichen. Um die verstrichene Zeit zu messen, zählt unser System abgespielte Audiosamples statt die <q>normale</q> Computeruhr zu nutzen, da sich so eine geringere <hi rend="italic">clock drift</hi> erzielen lässt. Um die Computer zu kalibrieren, wird die <hi rend="italic">clock drift</hi> einmal gemessen. Die Abweichung wird dann bei jedem Abspielen kompensiert. So kann eine Ausgangsabweichung von weniger als 1&#8239;ms und eine weitere Abweichung von weniger als 2&#8239;ms/h erreicht werden.<ref target="#Hadjakos2015" type="bibl" xml:id="bohl-ftn43" n="43" rend="ibid"/> Musikalisch sind diese Abweichungen unbedeutend.</p>
               <figure xml:id="bohl-fig03" rendition="#bohl-latex-width07">
                  <graphic url="figures/bohl-fig03.pdf" width="678px" height="323px"/>
                  <head type="legend">Abweichung von zwei Uhren um einen konstanten Wert (links) und Auseinanderdriften von zwei Uhren über die Zeit (rechts)</head>
               </figure>
               <p>Die Lösung mit dem <hi rend="italic">Distributed Button</hi> wurde in der App <hi rend="italic">sam</hi> realisiert. In dieser wird der wiedergegebene Click-Track zusätzlich optisch veranschaulicht, es wird der aktuelle Takt angegeben und die Noten werden automatisch <q>geblättert</q>. Die Anwendung ist somit primär auf die Konzertsituation eines verteilten Ensembles ausgerichtet, kann aber selbstverständlich auch bei der Probe eingesetzt werden.</p>
               <figure xml:id="bohl-fig04" rendition="#bohl-latex-width08">
                  <graphic url="figures/bohl-fig04.jpg" width="678px" height="323px"/>
                  <head type="legend">Synchronisierte Musik-Tablets</head>
               </figure>
               <p>Abb.&#x00A0;<ref target="#bohl-fig04" type="crossref" rend="no"/> zeigt acht synchronisierte Musik-Tablets. Die Tablets sind allesamt an den <hi rend="italic">Distributed Button</hi> angeschlossen, der auch bereits gedrückt wurde, sodass die Tablets in einen Countdown gehen, dessen Länge im Vorfeld eingestellt wurde. Die Tablets können nun wieder vom <hi rend="italic">Distributed Button</hi> getrennt werden und zu ihrem Einsatzort getragen werden. Dort beginnen sie nach Ablauf des Countdowns den Click-Track zu spielen und die Notenseiten automatisch fortzuschalten. Besonders erfreulich ist in diesem Zusammenhang, dass mit dieser Lösung keinerlei Abhängigkeit von vorhandenen oder dedizierten Funknetzen besteht, deren Vorhandensein oder Stabilität stark situationsabhängig sein kann.</p>
               <p>Unser System ist bisher bei drei Konzerten genutzt worden. Das erste Mal bei den Internationalen Ferienkursen für neue Musik in Darmstadt 2014. Zu diesem Anlass wurde die Uraufführung des Stückes <title level="m">à tue-tête</title> des Komponisten <name ref="#bohl-pers007">Fabien Lévy</name><note xml:id="bohl-ftn44" n="44"><name ref="#bohl-pers007">Fabien Lévy</name>,<title level="m"> à tue-tête</title>, Berlin 2014.
               </note> mit der Software <hi rend="italic">WebMaestro</hi> bei Proben und Konzert unterstützt. Des Weiteren wurde wie bereits eingangs erwähnt das Stück <title ref="#bohl-work003">Four tulips, two for you</title> von <name ref="#bohl-pers008">Matthias Mauch</name> aufgeführt. Hierbei wurden die beiden Musiker mit Hilfe zweier Laptops synchronisiert. Schließlich wurde im <hi rend="italic">Teatro di Poliziano</hi> in Montepulciano das unveröffentlichte Stück <title ref="#bohl-work004">Bild3</title> des Komponisten <name ref="#bohl-pers004">Maximiliano Estudies</name> mit Hilfe des in Abb.&#x00A0;<ref target="#bohl-fig04" type="crossref" rend="no"/> gezeigten Systems realisiert. Zusätzlich wurde bei diesem Konzert ein Laptop synchronisiert, mit dem ein mehrkanaliges Zuspiel realisiert wurde.</p>
               <p>Das System arbeitete in allen Fällen stabil und zuverlässig. Die Musiker lobten die einfache Konfigurierbarkeit des Click-Tracks in <hi rend="italic">WebMaestro</hi>, insbesondere die Möglichkeit, das Gesamttempo ad hoc anpassen zu können, ohne alle Tempobereiche individuell anpassen zu müssen. Durch die flexible Einbindung von Tablets und Laptops gleichermaßen lassen sich auch komplexe elektroakustische Setups realisieren. Darüber hinaus werden neue Perspektiven für Komponisten neuer Musik eröffnet, sei es für verteilte Konzerte oder für Klanginstallationen.</p>
            </div>
         <div xml:id="bohl-div05">
            <head>Digitale Noten in der Musikproduktion</head>
            <p>Im Zeitalter der technischen Reproduzierbarkeit von Musik<note xml:id="bohl-ftn45" n="45">Vgl. <ref target="#Benjamin1980" type="bibl"/>.
               </note> endet der musikalische Schaffensprozess nicht mit der Aufführung des Notenmaterials. Vielmehr kulminiert er im Prozess der <hi rend="italic">Musikproduktion</hi>, in dessen Zentrum der Tonmeister auf ganz eigene Art und Weise mit dem Notenmaterial arbeitet. Digitale Noten und Musikeditionen legen die Grundlage für eine noch engere Verzahnung von Noteninformationen mit den Arbeitsprozessen in der Musikproduktion. Dies soll im Folgenden an einigen Beispielen veranschaulicht werden, welche zugleich Themenstellungen aktueller Forschungs- und Entwicklungsprojekte in diesem Feld wiederspiegeln.</p>
            <p>Der Begriff <hi rend="italic">Musikproduktion</hi> umfasst in der klassischen Musik den gesamten Aufnahme- und Herstellungsprozess eines musikalischen Werkes zu dessen nachträglicher, möglichst klangtreuen Wiedergabe. Technisch betrachtet war dieser Prozess in den letzten 30&#x00A0;Jahren parallel mit den Fortschritten der Computertechnik einem rasanten Wandel unterworfen. Analoge Mischpulte wurden durch digitale Pendants ersetzt, Bandmaschinen von modernen Computern verdrängt. War der finanzielle Aufwand für qualitativ hochwertige Aufnahmen selbst in den späten 80er&#x00A0;Jahren noch auf einem für Privatpersonen beinahe undenkbaren Niveau, sind heutzutage Computersysteme aufgrund ihres enormen gesteigerten Preis-Leistungs-Verhältnisses zum alltäglichen Werkzeug in der Musikproduktion geworden.</p>
            <p>Trotz dieser Entwicklungen ist der Fokus des künstlerischen Aufnahmeleiters (<q>Tonmeister</q>) in der klassischen Musikproduktion traditionell geblieben. Als Bindeglied zwischen Musiker und aufgenommener Musik obliegt ihm sowohl eine Verantwortung gegenüber der Komposition als auch dem produzierten Gesamtwerk. Dies schließt sowohl die musikalisch-künstlerische wie technische Einflussnahme in allen Produktionsschritten ein, immer ausgerichtet auf die Erzielung des bestmöglichen Gesamtergebnisses. Ständiger Begleiter und wichtigstes Arbeitsutensil des Tonmeisters ist während des gesamten Prozesses die Partitur. Doch selbst in Zeiten von Touchscreens und Tablets liegt diese weiterhin in gedruckter Form vor. Die für spätere Arbeitsschritte essentiellen Eintragungen und Kommentare des Tonmeisters werden weiterhin mit Stift auf Papier vorgenommen, die Kommunikation mit dem Musiker erfolgt immer noch durch gesprochene Angaben von Seitennummer, System, Takt, Zählzeit etc.</p>
            <p>Durch die konsequente Digitalisierung der musikeditorischen Praxis werden für die Musikproduktion Grundlagen gelegt, die diese Arbeitsweise maßgeblich verändern und zum Teil erheblich vereinfachen können. Die Darstellung des Notentextes auf modernen Tablets ist hierbei nur der erste Schritt. Diese lässt sich nicht nur flexibel an die projektbezogenen oder persönlichen Bedürfnisse anpassen, z.&#8239;B. durch Änderung der dargestellten Notengröße oder flexible Anordnung der Partitursysteme, sondern ermöglicht zudem auch neue Kommunikationsformen mit den aufzunehmenden Musikern. Bereits verfügbare Notenständer-Apps wie <hi rend="italic">neoScores</hi><note xml:id="bohl-ftn46" n="46">Vgl. <ref target="#neoScores2015" type="bibl"/></note> erlauben den Austausch von digitalen Eintragungen in den Noten über mehrere Tablets hinweg, sodass beispielsweise Stimmführer die für ihre gesamte Instrumentengruppe relevanten Informationen eintragen können und diese automatisch auf den Anzeigen seiner Mitspieler synchronisiert werden. Ebenso könnte der Aufnahmeleiter während einer Produktion Noten oder Passagen auf seinem Tablet hervorheben, die auf den Tablets der Musiker gleichermaßen akzentuiert erscheinen. Dieser Vorgang kann bei konsequenter Nutzungsweise den auf beiden Seiten stattfindenden Suchprozess im Notentext vereinfachen und gleichzeitig merklich beschleunigen.</p>
            <p>Für die nachträgliche Bearbeitung des aufgenommenen Materials bietet die digitale Notenform noch erheblich weitreichendere Vorteile. Vom Tonmeister vorgenommene Eintragungen im Notentext (rot, siehe Abb.&#x00A0;<ref target="#bohl-fig05" type="crossref" rend="no"/>) können mit entsprechender Software erfasst und direkt mit der korrespondierenden zeitlichen Position im aufgenommenen Audiomaterial verknüpft werden. Ein ständiges Wechseln zwischen der üblichen Wellenformdarstellung der Aufnahme und den Noten könnte somit obsolet werden und den Fokus wieder stärker auf die Noten richten.</p>
            <figure xml:id="bohl-fig05">
               <graphic url="figures/bohl-fig05.png" width="2789px" height="1251px"/>
               <head type="legend">Entwurf für die verknüpfte Darstellung von Notenbild, Annotationen und Aufnahmetakes</head>
            </figure>
            <p>Im anschließenden Arbeitsschritt, dem Schnitt, erleichtert diese Verknüpfung das Auffinden der gesuchten Takes. Denkbar ist, dass man gewünschte Passagen innerhalb der dargestellten Take-Balken (siehe Abb.&#x00A0;<ref target="#bohl-fig06" type="crossref" rend="no"/>) markieren (hier: gelb) und in den finalen Schnitt übernehmen kann. Auf diese Weise bleibt der Bezug zu den Noten stets erhalten und bietet eine auf einen Blick erfassbare Schnittfassung.</p>
            <figure xml:id="bohl-fig06">
               <graphic url="figures/bohl-fig06.pdf" width="678px" height="323px"/>
               <head type="legend">Entwurf eines Oberflächenkonzepts für den musikalischen Schnitt</head>
            </figure>
            <p>Die vollständige Umstellung auf einen derartigen digitalen Arbeitsprozess kann sowohl den Produktionsprozess übersichtlicher und komfortabler gestalten als auch die anschließende Dauer für die Verarbeitung des Rohmaterials reduzieren. So können digitale Noten und Editionen zu inhärenten Bausteinen künftiger Werkzeuge und Arbeitsprozesse in der Musikproduktion werden.</p>
         </div>
         <div xml:id="bohl-div06">
            <head>Auf zur nächsten Runde</head>
            <p>Die Belange der Musikedition erschöpfen sich nicht in der Anfertigung der Edition an sich. Eine Edition bliebe bedeutungslos, die investierte oft mehrjährige Arbeit vergebens, ohne ihre Nutzer, welche bei Weitem nicht nur die ausführenden Musiker sind, sondern auch Tonmeister, Musikwissenschaftler, -informatiker und -enthusiasten. Wer die Belange und Erfordernisse dieser Nutzergruppen nicht im Blick behält, droht, an seinen Zielgruppen vorbei zu arbeiten und im <q>editionswissenschaftlichen Elfenbeinturm</q> in Vergessenheit zu geraten. Die <hi rend="italic">digitale</hi> Musikedition kommt der Vielfältigkeit der Nutzungskontexte nicht nur entgegen, sie befeuert sie sogar noch. Etliche Beispiele wurden in den vorangegangenen Abschnitten angeführt, zwei davon exemplarisch detaillierter ausgeführt. Ebenso wie diese Liste nicht abschließend sein kann, ist die Entwicklung der digitalen Musikedition längst nicht an ihrem Endpunkt angelangt. Ihre Arbeitsprozesse (derzeit noch sehr ähnlich denen der traditionell analogen Musikedition), ihre Werkzeuge und die Beschaffenheit ihrer Resultate (Formate und korrespondierende Datenstrukturen) sowie die Art und Weise ihrer medialen Präsentation (gedruckter oder digitaler Notentext, Einbezug von Ton und Bewegtbild, statisch oder interaktiv) werden sich auch in Zukunft weiter wandeln.</p>
            <p>Mit dem Schritt ins Digitale hat der Editionsigel einen großen Schritt gemacht, mit dem er zum vorauseilenden Programmierhasen aufgeschlossen hat. Es ist zu wünschen, dass dies in Zukunft mehr als bislang zu einem regen Austausch, gemeinsamer Arbeit und innovativen Ideen inspiriert. Schließlich konserviert die Musikedition nicht nur die kulturellen Errungenschaften der Vergangenheit, sondern trägt zum kulturellen Leben der Zukunft bei.</p>
         </div>
      </body>
      <back>
         <div type="bibliography">
            <listBibl>
               <bibl xml:id="Grimm1977"><title level="a">Der Hase und der Igel</title>, in: <title level="m">Jacob und Wilhelm Grimm, Kinder- und Hausmärchen. Gesammelt durch die Brüder Grimm</title>, München 1977, DOI: <ref target="http://doi.org/hdl:11858/00-1734-0000-0003-03B2-E">hdl:11858/00-1734-0000-0003-03B2-E</ref></bibl>
               <bibl xml:id="Veit2003-bohl">Joachim Veit, <title level="a">Hase oder Igel? &#x2013; Musikedition und neue Medien</title>, in: <title level="m"><q>Alte</q> Musik und <q>neue</q> Medien</title>, hg. von  Jürgen Arndt und Werner Keil, Hildesheim u.&#8239;a. 2003 (Diskordanzen. Studien zur neueren Musikgeschichte&#x00A0;14)<bibl type="short">Veit, <title level="a">Hase oder Igel?</title></bibl></bibl>
               <bibl xml:id="Edirom2007">Johannes Kepper und Daniel Röwenstrunk, <title level="a">Das Edirom-Projekt. Werkzeuge für digitale Formen wissenschaftlich-kritischer Musikeditionen</title>, in: <title level="m">Forum Musikbibliothek</title>, 28 (2007), S.&#8239;36&#x2013;49</bibl>
               <bibl xml:id="Hitzler2008">Pascal Hitzler, Markus Krötzsch, Sebastian Rudolph und York Sure, <title level="m">Semantic Web. Grundlagen</title>, Berlin u.&#8239;a. 2008</bibl>
               <bibl xml:id="DFG_Standardbildung2013">Deutsche Forschungsgemeinschaft, <title level="m">Standardbildung für die Erschließung und/oder Digitalisierung von Objektgattungen in wissenschaftlichen Sammlungen</title>, Bonn 2013 (Information für die Wissenschaft Nr.&#8239;08), URL: <ptr target="http://www.dfg.de/foerderung/info_wissenschaft/2013/info_wissenschaft_13_08/index.html"/></bibl>
               <bibl xml:id="Stock2015">Günter Stock und Sebastian Zwies, <title level="a">Nachwuchsförderung im Akademienprogramm</title>, in: <title level="m">Akademie Aktuell</title> 03&#x2013;2015</bibl>
               <bibl xml:id="MEI_2-1-1"><title level="m">MEI Guidelines Version 2.1.1</title>, 2014, URL: <ptr target="http://music-encoding.org/documentation/2.1.1/chapters/"/></bibl>
               <bibl xml:id="Kepper2011">Johannes Kepper, <title level="m">Musikedition im Zeichen neuer Medien &#x2013; Historische Entwicklung und gegenwärtige Perspektiven musikalischer Gesamtausgaben</title>, Norderstedt 2011<!-- (zugleich Diss. Universität Paderborn 2009)--><bibl type="short">Kepper, <title level="m">Musikedition im Zeichen neuer Medien</title></bibl></bibl>
               <bibl xml:id="Friedlaender1907">Max Friedlaender, <title level="a">Über die Herausgabe musikalischer Kunstwerke</title>, in: <title level="m">Jahrbuch der Musikbibliothek Peters</title>, hg. von Rudolf Schwartz, 14 (1907), Leipzig 1908</bibl>
               <bibl xml:id="Goetzelmann2008">Timo Götzelmann, <title level="m">Correlating Illustrations and Text through Interactive Annotation</title>, Saarbrücken 2008<!-- (zugleich Diss. Otto-von-Guericke-Universität Magdeburg, 2008)--></bibl>
               <bibl xml:id="Schloots2015">Franziska Schloots, <title level="m">Wissenschaftliche Arbeit und Kommunikation von Musikeditoren im deutschsprachigen Raum</title> (Masterarbeit), Universität Paderborn 2015</bibl>
               <bibl xml:id="FreiDi2013"><title level="m">Freischütz Digital. Hintergründe und Impressionen zur Aufnahme dreier Nummern des Freischütz an der HfM Detmold</title>, Detmold 2013, online abrufbar unter <ptr target="http://www.freischuetz-digital.de/audio-recording-2013.html"/></bibl>
               <bibl xml:id="FreiDi2014"><title level="m">Freischütz Digital. Abschluss der Audio-Produktion am ETI der HfM Detmold</title>, Detmold 2014, online abrufbar unter <ptr target="http://freischuetz-digital.de/audio-production-2014.html"/></bibl>
               <bibl xml:id="Berndt2015">Axel Berndt, <title level="a">Formalizing Expressive Music Performance Phenomena</title>, in: <title level="m">Works in Audio and Music Technology</title>, hg. von Axel Berndt, Dresden 2015, S.&#8239;97&#x2013;128</bibl>
               <bibl xml:id="Haehnel2013">Tilo Hähnel, <title level="m">Baroque performance &#x2013; a research study on characteristic parameters of eighteenth century music performance</title>, Osnabrück 2013 (Studies in Cognitive Musicology&#x00A0;2)</bibl>
               <bibl xml:id="Posch1999">Marco Ambrosini und Michael Posch, <title level="m">Einführung in die mittelalterliche Musik</title>, Reichelsheim <edition>3</edition>1999</bibl>
               <bibl xml:id="Denhoff1988">Michael Denhoff, <title level="a">Stille und Umkehr &#x2013; Betrachtungen zum Phänomen Zeit</title>, in: <title level="m">MusikTexte. Zeitschrift für neue Musik</title>&#x00A0;24 (1988), S.&#8239;27&#x2013;38</bibl>
               <bibl xml:id="Dickinson1989">Peter Dickinson, <title level="a">Style-modulation: an approach to stylistic pluralism</title>, in: <title level="m">The Musical Times</title>&#x00A0;130 (1989), S.&#8239;208&#x2013;211</bibl>
               <bibl xml:id="Berndt2011">Axel Berndt, <title level="m">Musik für interaktive Medien: Arrangement- und Interpretationstechniken</title>, München 2011<!-- (zugleich Diss. Otto-von-Guericke Universität, Magdeburg 2011)--></bibl>
               <bibl xml:id="Cope1996">David Cope, <title level="m">Experiments in Musical Intelligence</title>, Middleton  1996</bibl>
               <bibl xml:id="Gabrieli1597">Giovanni Gabrieli, <title level="m">Sacrae Symphoniae</title>, Venedig 1597</bibl>
               <bibl xml:id="Barrett2007">Natasha Barrett, <title level="a">Trends in electroacoustic music</title>, in:  <title level="m">The Cambridge Companion to Electronic Music</title>, hg. von Nick Collins und Julio d’Escriván, Cambridge 2007, S.&#8239;232–255</bibl>
               <bibl xml:id="Weibel1987">Peter Weibel, <title level="a">Der freie Klang zwischen Schweigen, Geräusch und Musik</title>, in: <title level="m">MusikTexte. Zeitschrift für neue Musik</title>&#x00A0;21 (1987), S.&#8239;33–38</bibl>
               <bibl xml:id="Chafe2004">Chris Chafe und Michael Gurevich, <title level="a">Network Time Delay and Ensemble Accuracy: Effects of Latency, Asymmetry</title>, in: <title level="m">Proceedings of the Audio Engineering Society 117. Conference</title>, San Francisco 2004, online abrufbar unter <ptr target="http://chrischafe.net/wp-content/uploads/2014/08/netTimeDel.pdf"/></bibl>
               <bibl xml:id="Chew2004">Elaine Chew, Roger Zimmermann, A.&#8239;A. Sawchuk, Chris Kyriakakis, Christos Papadopoulos, Alexandre R.&#8239;J. François, G. Kim, A. Rizzo und A. Volk, <title level="a">Musical Interaction at a Distance: Distributed Immersive Performance</title>, in: <title level="m">Proceedings of the 4th Open Workshop of MUSICNETWORK: Integration of Music in Multimedia applications</title>, Barcelona 2004, online abrufbar unter <ptr target="http://www.researchgate.net/publication/228726054_Musical_interaction_at_a_distance_Distributed_immersive_performance"/></bibl>
               <bibl xml:id="Benyon2010">David Benyon, <title level="m">Designing Interactive Systems: A comprehensive guide to HCI and interaction design</title>, Harlow <edition>2</edition>2010, S.&#8239;26–48<bibl type="short">Benyon, <title level="m">Designing Interactive Systems</title></bibl></bibl>
               <bibl xml:id="Hadjakos2015">Aristotelis Hadjakos, Axel Berndt und Simon Waloschek, <title level="a">Synchronizing Spatially Distributed Musical Ensembles</title>, in: <title level="m">Proceedings of the 12th International Conference on Sound and Music Computing (SMC-15)</title>, Maynooth 2015, S.&#8239;96–97<bibl type="short">Hadjakos/Berndt/Waloschek, <title level="a">Synchronizing Spatially Distributed Musical Ensembles</title></bibl></bibl>
               <bibl xml:id="neoScores2015">neoScores bvba, neoScores. <title level="m">The digital alternative to sheet music. Done right. Use neoScores to get rid of sheet music on paper</title>, Kontich 2015, online abrufbar unter <ptr target="https://www.neoscores.com/"/></bibl>
               <bibl xml:id="Blattner1989">Meera M. Blattner, Denise A. Sumikawa und Robert M. Greenberg, <title level="a">Earcons and icons: Their structure and common design principles</title>, in: <title level="m">Human–Computer Interaction</title>&#x00A0;4 (1989), S.&#8239;11&#x2013;44</bibl>
               <bibl xml:id="Benjamin1980">Walter Benjamin, <title level="a">Das Kunstwerk im Zeitalter seiner technischen Reproduzierbarkeit</title>, <!--1939 deutsche Fassung,--> in: Walter Benjamin, <title level="m">Gesammelte Schriften</title>, Bd.&#8239;I, Frankfurt am Main 1980</bibl>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
