<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="../schemata/cgrid.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="../schemata/cgrid.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main">Die Spuren des Digitalen</title>
            <title type="sub">Über die Nachnutzbarkeit digitaler Inhalte</title>
            <author>
               <name><forename>Maja</forename> <surname>Hartwig</surname></name>
               <email/>
               <affiliation>studierte Musikwissenschaft mit den Nebenfächern Germanistische Sprachwissenschaft und Pädagogik an der Universität Paderborn und dem Musikwissenschaftlichen Seminar Detmold/Paderborn. 2010 Magister Artium mit einer Arbeit zum Thema <hi rend="italic">Musikalischer Widerstand im Nationalsozialismus</hi>. 2010 bis 2013 wissenschaftliche Hilfskraft im DFG/NEH-geförderten Projekt <hi rend="italic">Digital Music Notation Data Model and Prototype Delivery System</hi>. 2013 bis 2014 wissenschaftliche Mitarbeiterin im BMBF-Projekt <hi rend="italic">Digital Research Infrastructures for the Arts and Humanities</hi> (DARIAH-DE). Seit 2014 arbeitet sie im Projekt <hi rend="italic">Beethovens Werkstatt</hi>.</affiliation>
            </author>
            <author>
               <name><forename>Johannes</forename> <surname>Kepper</surname></name>
               <email/>
               <affiliation>studierte Musikwissenschaft, Medienwissenschaft und Informatik am Musikwissenschaftlichen Seminar Detmold/Paderborn und der Universität Paderborn. 2003 bis 2012 Mitarbeiter im DFG-Projekt <hi rend="italic">Digitale Musikedition (Edirom)</hi>. Seit 2006 aktive Mitarbeit an der Formatentwicklung der <hi rend="italic">Music Encoding Initiative</hi> (MEI), seit Ende 2014 Administrative Chair des MEI Boards. 2009 Promotion mit einer Arbeit zu <hi rend="italic">Musikedition im Zeichen neuer Medien</hi>. 2010 bis 2013 Leitung des Projekts <hi rend="italic">Digital Music Notation Data Model and Prototype Delivery System</hi>. 2012 bis 2014 Mitarbeiter im BMBF-Projekt <hi rend="italic">Freischütz Digital</hi>. Seit 2014 arbeitet er im Projekt <hi rend="italic">Beethovens Werkstatt</hi>.</affiliation>
            </author>
         </titleStmt>
         <publicationStmt>
            <publisher>Virtueller Forschungsverbund Edirom (ViFE)</publisher>
            <availability>
               <licence target="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License (CC BY 4.0)</licence>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>Converted from a Word document</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <langUsage>
            <language ident="de"/>
         </langUsage>
         <particDesc>
            <listPerson>
               <person xml:id="beethoven-pers001">
                  <p>Tomasello, Michael</p>
               </person>
            </listPerson>
         </particDesc>
      </profileDesc>
      <revisionDesc>
         <change when="2015-11-19T16:16:00"
            who="https://github.com/peterstadler">Interne Korrekturen eingearbeitet.</change>
         <change when="2015-11-18T14:35:54.096+01:00"
                 who="https://github.com/peterstadler">Initial transformation from OxGarage TEI P5 to jTEI customization.</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div type="abstract" xml:id="beethoven-abstract">
            <p>Digitale Editionsprojekte hinterlassen medienspezifische Spuren, die weit mehr Rückschlüsse auf ihre Konzepte, Arbeitsweisen und Erkenntnisse bieten, als dies bei gedruckten Ausgaben möglich war und ist. Diese Einblicke in ein Projekt sind für zukünftige Forschungsvorhaben von großem Wert, erleichtern sie doch das Verständnis und bieten Hintergrundinformationen zu bestimmten Entscheidungen, die zumindest in dieser Ausführlichkeit nicht Bestandteil der eigentlichen Edition sind. In der Summe aber lässt sich so der Anteil der erarbeiteten Erkenntnisse, die auch in die Publikation(en) des Projekts eingehen, deutlich steigern, was letztlich zu einer erhöhten wissenschaftlichen Transparenz, Nachnutzbarkeit und Nützlichkeit der eigenen Forschungsleistung führt.
               Welche Spuren digitale Methoden innerhalb der Projekte hinterlassen und inwiefern diese nachgenutzt werden können, soll in diesem Betrag anhand einiger Beispiele diskutiert werden.</p>
         </div>
      </front>
      <body>
         <pb n="319"/>
            <div xml:id="beethoven-div01">
               <head>Einleitung</head>
               <p>Eine in der heutigen Zeit zuweilen häufig aufgestellte Behauptung ist die verbesserte Nachnutzbarkeit digitaler Editionen gegenüber denen der traditionellen gedruckten Ausgaben. Denn zukünftige Arbeiten am gleichen Inhalt müssten demnach nicht mehr bei Null beginnen, sondern könnten direkt auf den Ergebnissen einer aktuellen Ausgabe ansetzen. Selbst wenn man bei dieser Frage technische Unberechenbarkeiten  &#x2013; hier seien nur die Stichworte Langzeitarchivierung und wechselnde Datenformate genannt &#x2013; außer Acht lässt, so bleiben doch berechtigte Zweifel, ob für künftige Generationen tatsächlich ein goldenes Editionszeitalter beginnt, wie es digitale Möglichkeiten mitunter erscheinen lassen.</p>
               <p>Im Folgenden wollen wir uns der Fragestellung widmen, welche Spuren die aktuellen digitalen Methoden nachweisbar hinterlassen und wie sie sich von denen früherer Arbeitsweisen unterscheiden. Ausgehend von der Frage der Verwertbarkeit dieser Spuren, sollen anschließend Überlegungen zu deren Verfügbarkeit oder gar besserer Erkennbarkeit für unsere Nachwelt angestellt werden.</p>
               <p>Die aufgeführten Beispiele werden sich zwischen Best und Worst Practice  bewegen, sollen aber möglichst ein realitätsnahes Bild der aktuellen Situation wiedergeben. Weiterhin werden sich diese Beispiele auf eine Auswahl innerhalb des Autorenumfeldes beschränken, sind aber dennoch sicherlich auf andere Projekte und ähnliche Problemstellungen übertragbar. Die Autoren nehmen ausdrücklich nicht für sich in Anspruch, als Vorbild zu taugen &#x2013; vielmehr wird dieser Artikel als Eigenmahnung verstanden.</p>
            </div>
         <div xml:id="beethoven-div02">
               <head>Spurensuche</head>
            <p>Ein wesentliches Merkmal Digitaler Editionen ist der Gebrauch von Faksimiles und/oder Codierungen von deren Inhalten. Dabei <q>entstehen keineswegs zwingend <soCalled>bessere</soCalled> Editionen, aber die jeweilige wissenschaftliche Arbeit lässt sich leichter nachvollziehen und bewerten</q>.<ref target="#Kepper2009" type="bibl" xml:id="beethoven-ftn2" n="2">S.&#8239;197</ref> 
               Im Gegensatz zu gedruckten Ausgaben geht damit gleichzeitig die berechtigte Hoffnung einher, die abschließende Publikation beherberge einen großen Teil der wissenschaftlichen Arbeit, womit sie gleichermaßen für nachfolgende Forschungen zur Verfügung stünde. </p>
               <p>Betrachtet man die traditionellen tabellarischen Lesartenverzeichnisse und gleicht deren Informationsgehalt mit dem Erkenntnisgewinn des Editors bei dessen Erarbeitung ab, so ist die <soCalled>Verwertungsquote</soCalled> in der Regel betrüblich gering. Nur selten gehen die Einträge über das Deskriptive hinaus, die Frage nach dem <q>Warum?</q> der beobachteten Unterschiede ist nicht allein aufgrund des Platzmangels im Buchformat ohne extensiven Einsatz von Faksimiles so komplex, dass sie kaum je gewinnbringend verhandelt werden kann. Nichtsdestotrotz wird sich der Herausgeber mit all diesen Fragen auseinandergesetzt haben müssen, um zu (zumindest für ihn) überzeugenden Entscheidungen gekommen zu sein. All diese Überlegungen finden sich aber im gedruckten Band nicht mehr wieder, alle Abwägungen und (Gegen-)Argumente sind endgültig verloren, die Spuren des Editors sind demnach verwischt oder gänzlich unkenntlich gemacht. </p>
               <p>Wird nun dieses edierte Werk zum Gegenstand einer weiteren Ausgabe, so kann der spätere Herausgeber nur auf die Ergebnisse der vorhergehenden Edition zurückgreifen, nicht aber auf den dorthin führenden <q>Weg der Erkenntnis</q>. Um diese Ergebnisse nachvollziehen zu können, führt in diesem Fall kein Weg an einer neuerlichen Beschäftigung mit den Quellen vorbei, da frühere Entscheidungswege des Editors rekonstruiert werden müssen. Dies wird mitunter zu einer philologischen Herausforderung, welche unbezwingbar erscheint und die Frage aufkommen lässt, ob eine Edition tatsächlich zu einer Arbeitserleichterung für spätere Vorhaben wird.</p>
               <p>Im gegenwärtigen Idealbild einer Digitalen Edition hat sich die Vorstellung einer inhaltlichen Codierung etabliert, welche in Verknüpfung mit zugehörigen Faksimiles die mögliche Subjektivität der Ausgaben zwar nicht vollständig behebt, aber doch so transparent werden lässt, dass alle Entscheidungen des Editors sichtbar und nachvollziehbar gemacht werden könnten. <!--</p>
            <p>-->Letztlich zielt dieser Gedanke auf den Wagenheber-Effekt von <name ref="#beethoven-pers001">Michael Tomasello</name>,<ref type="bibl" target="#Tomasello1999" xml:id="beethoven-ftn3" n="3"/> also <q>das Konstruktionsprinzip, nach dem die wiederholte Kraftanwendung jeweils auf den letzten erreichten Zustand wirkt.</q><ref target="#Eibl2003" type="bibl" xml:id="beethoven-ftn4" n="4">S.&#8239;575</ref> Gleichsam ohne Verluste sollen so die gewonnenen Erkenntnisse über das eigene Projekt hinaus Bestand haben und zukünftigen Forschergenerationen zumindest als Arbeitserleichterung, wenn nicht -grundlage dienen können, eine Spurensuche also überhaupt erst möglich machen. </p>
               <p>Daraus ergibt sich die Frage, ob und in welchem Maße diese Hoffnungen berechtigt sind. </p>
         </div>
            <div xml:id="beethoven-div03">
               <head>Welche Arbeitsweisen Spuren hinterlassen können</head>
               <p>Zunächst können hier die publizierten Forschungsdaten genannt werden. Dabei handelt es sich im Rahmen von Musikeditionen in erster Linie um MEI- bzw. TEI-Codierungen sowie Bilddateien. Zumindest erstere sollten in einer Digitalen Edition direkt, d.&#8239;h. in <soCalled>Rohform</soCalled> verfügbar sein. Sie entsprechen dem Kritischen Bericht der gedruckten Ausgaben, gehen aber in ihrer inhaltlichen Bandbreite über dessen Informationsgehalt weit hinaus. Im Abgleich von Codierung und verknüpftem Faksimile kann der Benutzer einer solchen idealisierten Ausgabe jederzeit nachvollziehen, worauf die (weiterhin subjektive) Interpretation des Editors basiert. Das Projekt <hi rend="italic">Beethovens Werkstatt</hi> bearbeitete als erstes Beispiel eine Variantenstelle aus Op.&#8239;111 des Komponisten und stieß in dessen Autograph<note xml:id="beethoven-ftn5" n="5">Das Arbeitsmanuskript befindet sich heute im Beethoven-Haus Bonn (BH 71).</note> 
                  auf eine Abfolge von Noten, deren Tondauern jedoch von Beethoven nicht eindeutig notiert worden waren und somit von den Mitarbeitern nicht eindeutig identifiziert werden konnten.</p>
               <!--<p>
                  <hi rend="bold">[hier Screenshot S.&#8239;17, mit Bildunterschrift: <q>L. v. Beethoven: Klaviersonate op. 111, Autograph (Beethoven-Haus Bonn, BH 71), Seite 17. Zu sehen ist Takt 133f des Manuskripts, in dem Beethoven einen Variantenentwurf skizziert, aber unmittelbar wieder verwirft. </q>]</hi>
               </p>-->
               <p>Aus dem Kontext wird deutlich, dass es sich bei den hier gezeigten Noten um 16tel handeln muss, so dass in der editorischen Aufbereitung im Einklang mit den Richtlinien des Projekts letztlich nur diese Interpretation angeboten wird, ohne gesondert auf den Umstand dieser Auslegung hinzuweisen. Tatsächlich könnten in der Codierung auch mehrere alternative Interpretationen angeboten und entsprechend nachvollzogen werden.<note xml:id="beethoven-ftn6" n="6">Dabei handelt es sich allerdings bislang um eine theoretische Möglichkeit; den Verfassern sind bis dato keine Ausgaben bekannt, die von dieser im theoretischen Diskurs immer wieder vorgebrachten Möglichkeit Gebrauch machen würden. Gegen deren Einsatz spricht wohl ein auf allen Ebenen signifikant erhöhter Aufwand: In der Benutzeroberfläche müssten Wege gefunden werden, diese <soCalled>Unentschlossenheit</soCalled> des Herausgebers dem Benutzer angemessen zu vermitteln. Damit dürfte auch die technische Auswertung der Editionsdaten deutlich komplexer werden. Nicht zuletzt verkompliziert sich aber der Aufwand zur Erstellung der Codierungen in nicht unerheblicher Weise: Zwar ist das für einen solchen Zweck nötige Markup recht überschaubar &#x2013; im Wesentlichen handelt es sich um den zusätzlichen Gebrauch des <gi>choice</gi>-Elements in MEI &#x2013; dadurch werden allerdings wesentlich komplexere Workflows notwendig, um mit solchen Daten weiterhin effizient umgehen zu können. Die Erfahrungen des Projekts <hi rend="italic">Freischütz Digital</hi> haben dabei gezeigt, das gerade solche Komplexitätssteigerungen der Codierungsmodelle die bereits bestehenden Werkzeuge und Workflows überfordern und in einen immensen Mehraufwand resultieren.</note> 
                  Allerdings werden auch in diesem Fall lediglich die Ergebnisse des editorischen Erkenntnisprozesses angeboten, während die auf dem Weg dorthin stattgefundenen Diskussionen, erwogenen Alternativen und vorgebrachten Argumente weiterhin nicht zwingend Bestandteil der publizierten Edition sind.<note xml:id="beethoven-ftn7" n="7">Selbstverständlich gibt es grundsätzlich die Möglichkeit, diese Alternativen in den editorischen Anmerkungen vorzustellen und zu diskutieren. Ob ein Editor hier aber tatsächlich in absoluter Offenheit auch alle Gegenargumente zu seiner anderslautenden Entscheidung für den edierten Text &#x2013; den er mit seiner Anmerkung ja rechtfertigen will &#x2013; in ähnlich überzeugender Weise vorbringt, darf zumindest bezweifelt werden.</note> 
                  Damit hat sich zwar die Fülle an vorhandenen Informationen ebenso verändert wie die Transparenz bzw. Nachvollziehbarkeit der editorischen Entscheidungen, die editorische Arbeit hingegen bleibt zumindest in der Publikation weiterhin unsichtbar. Nachnutzende Projekte können damit eben nicht in einen imaginären Dialog mit ihren Vorgängern treten, sondern müssen weiterhin deren Arbeit vom Ergebnis her rekonstruieren. </p>
            </div>
            <div xml:id="beethoven-div04">
               <head>Versionsverwaltung</head>
               <p>Mit der Erarbeitung einer Digitalen Edition fällt eine überaus große Menge an Daten an, die den editorischen Prozess dokumentieren sollen und nachnutzenden Projekten von großer Bedeutung sein können. An erster Stelle steht hier die genutzte Versionsverwaltung von Daten, bzw. deren Commit Messages. In dieser Versionsverwaltung &#x2013; im Detmolder Kontext wird dazu in der Regel <hi rend="italic">Subversion</hi> (SVN) genutzt &#x2013; werden die Forschungsdaten sukzessive und kumulativ aufgebaut. Dabei ist jeder einzelne Zwischenstand rekonstruierbar und durch besagte Commit Messages dokumentiert. Diese kurzen Nachrichten dienen dazu, die Änderungen der jeweiligen Revision zusammenzufassen und so einen schnelleren Zugriff auf bestimmte Datenstände zu gewähren, ohne diese manuell sichten und vergleichen zu müssen. Voraussetzung dafür ist die Aussagekraft einer solchen Commit Message. Obgleich es sich hierbei um interne Arbeitsnotizen handelt, die nicht für die Öffentlichkeit bestimmt sind, gibt es in deren Gebrauch gravierende Unterschiede. Im Rahmen des Projekts <hi rend="italic">Freischütz Digital</hi> wurden mittlerweile weit über 2.000&#x00A0;Revisionen erzeugt. Dabei konnte der Anteil derjenigen Commit Messages, die tatsächlich Text enthalten, kontinuierlich gesteigert werden; er liegt inzwischen bei etwa 90&#8239;%. Das bedeutet aber gleichzeitig, dass noch knapp ein Zehntel aller Eingriffe ohne (stichwortartige) Zusammenfassung erfolgt. Auch täuscht die recht hohe Zahl eine Brauchbarkeit der Informationen vor, die nicht immer gegeben ist. Eine Nachricht, die lediglich aus dem Wort <q>korr</q> besteht, bietet über den Hinweis auf Änderung bestehender Dateien (in Abgrenzung zum Hinzufügen neuer Inhalte) wenig Aussagekraft: diese Information ist beinahe ebenso schnell durch die technischen Metadaten zum jeweiligen Commit<note xml:id="beethoven-ftn8" n="8">Subversion liefert eine Liste aller im Rahmen einer Revision modifizierten, gelöschten und neu hinzugekommenen Dateien. Für die modifizierten Dateien lässt sich dann ein direkter Vergleich z.&#8239;B. zur Vorgänger-Revision anstellen, bei dem gezielt die geänderten Stellen angesprungen werden können.</note> zu gewinnen. Berücksichtigt man den Informationsgehalt der einzelnen Commit Messages, verdoppelt sich der Anteil der nicht aussagekräftigen Nachrichten auf etwa 20&#8239;% der letzten 200 commits. Wählt man einen Vergleichsausschnitt vom Beginn des Projektes, ergeben sich zunächst weitaus höhere Werte, so dass ein Lerneffekt, ein Gewöhnen an den Umgang mit dieser Technik offenkundig stattgefunden hat. Tatsächlich ist allerdings zu beobachten, dass sich die Werte nochmals deutlich anders darstellen, wenn man sie nach Personen sortiert, denn Subversion zeigt ebenfalls an, wer für einen commit verantwortlich ist. Es ist zu beobachten, dass Commit Messages von Personen mit größerem technischen Hintergrundwissen einen anderen Inhalt haben als solche von Mitarbeitern ohne dieses Hintergrundwissen. Eine mustergültige Commit Message ist zum Beispiel: <q>@artic normiert zu dot/stroke</q>. Durch eine solche Nachricht lässt sich, verbunden mit dem Wissen, an welchen Dateien gearbeitet wurde, schon recht genau nachvollziehen, welcher Art die vorgenommenen Änderungen sind. Gleichzeitig wird aber deutlich, dass es sich bei Commit Messages um sehr kontextbezogene Informationen handelt, die nicht dazu geeignet sind, den grundsätzlichen Aufbau der Daten zu erläutern. Stattdessen begleiten sie die Entstehung der Daten in ihrer Bewegung vom Unfertigen zum Fertigen; sie sind ein technisches Protokoll einzelner Arbeitsschritte,<note xml:id="beethoven-ftn9" n="9">Tatsächlich ist auch hier ein sehr uneinheitlicher Gebrauch zu beobachten: Manche commits gehen sehr feingliedrig vor, d.&#8239;h. es werden gezielt nur einzelne Änderungen in einzelnen Dateien eingecheckt, während andere ein Füllhorn an Eingriffen auch über mehrere Dateien hinweg bündeln und so deren Nachvollziehbarkeit deutlich einschränken. Hier eine gute Balance zu finden, bei der zwar Zusammengehöriges gemeinsam, ansonsten aber grundsätzlich möglichst feingranular eingecheckt wird, bleibt eine andauernde Herausforderung.</note> 
                  ihre Funktion entspricht eher der eines Bautagebuchs als dem Bauplan der behandelten Artefakte. Damit aber erlauben sie &#x2013; ihre Verfügbarkeit vorausgesetzt &#x2013; nachfolgenden Projekten einen in dieser Form bislang nicht möglichen Einblick in die tatsächliche Arbeit eines Projekts: In welcher Reihenfolge und zeitlichen Abfolge wurden die Daten aufgebaut? An welchen Stellen wurden Änderungen oder Umarbeitungen nötig? Wer verantwortete welche Bereiche der Ausgabe? All diese Fragen lassen sich grundsätzlich anhand einer Versionsverwaltung wie Subversion beantworten.</p>
               <p>Zusätzlich lassen sich in den beiden Formaten TEI und MEI auch innerhalb der Dateien selbst Änderungen protokollieren. Handelt es sich bei Commit Messages um sehr technische angelegte Informationen, sind an dieser Stelle die entsprechenden Eingriffe häufig eher inhaltlich erfasst. Da aber gerade bei manuellen Änderungen an den Forschungsdaten kein Automatismus die Erstellung dieser <gi>change</gi>-Elemente erzwingt, kommt es hier umso mehr auf die Disziplin der Projektmitarbeiter an. Bei zuverlässiger Eintragung aller Änderungen ergibt sich aber gerade in Kombination mit einer Versionsverwaltung ein überaus hilfreiches Protokoll des Werdegangs der Projektdaten.</p>
            </div>
            <div xml:id="beethoven-div05">
               <head>Projektmanagement</head>
               <p>Mit einem Projektmanagement (im Folgenden als PM abgekürzt) lassen sich in einzigartiger Weise Erkenntnisse über den Arbeitsprozess einer Digitalen Edition gewinnen. Wenn Subversion Zugriff auf die Bautagebücher gewährt, so fehlen noch immer die Baupläne der Edition. Diese setzen sich aus mehreren Komponenten zusammen, welche die Ausgabe in mehreren Abstraktionsgraden skizzieren. Den größten Zusammenhang zu den Bautagebüchern haben dabei die evtl. genutzten Arbeitsplanungen, die in Form von Tickets in einer Projektmanagement-Software<note xml:id="beethoven-ftn66">Im Detmolder Kontext wird i.&#8239;d.&#8239;R. <hi rend="italic">Redmine</hi> eingesetzt, vgl. <ptr target="http://www.redmine.org/"/></note> angelegt und einzelnen Mitarbeitern zur Bearbeitung zugewiesen werden. Während in Subversion die tatsächlichen Änderungen an den Dateien protokolliert werden, finden sich hier die Aufgabenbeschreibungen, Verantwortlichkeiten, sowie ggf. Arbeits- und Bearbeitungszeiten und Rückfragen des Bearbeiters. Eine solche Projektmanagement-Software ist gerade zur Koordination mehrerer Mitarbeiter von unschätzbarem Wert und erlaubt es, einen guten Überblick über den Stand der Arbeiten zu behalten. Allerdings setzt ihr Einsatz eine hohe Disziplin aller Beteiligten voraus &#x2013; sämtliche Tickets müssen nicht nur inhaltlich abgearbeitet, sondern auch als erledigt markiert werden. Problematisch wird es, wenn Aufgaben innerhalb von Besprechungen zum Beispiel persönlich verteilt werden und somit nicht im PM nachvollzogen werden können. Damit verliert dieses seinen Anspruch auf Vollständigkeit und bildet eben nicht mehr sämtliche zur Edition gehörigen Arbeitsschritte ab. Dieses Problem lässt sich am ehesten durch eine sorgfältig austarierte <q>Größe</q> der einzelnen Arbeitspakete beheben: Sind die einzelnen Arbeitspakete zu umfangreich, verliert die Projektmanagement-Software ihre Aussagekraft und Steuerungsfunktion, sind sie zu kleingliedrig, schreckt der damit verbundene Mehraufwand zur Protokollierung der einzelnen Arbeitsschritte leicht ab und verleitet zu einem nachlässigen Gebrauch. Neben der Möglichkeit das Ticketsystem zu nutzen, bietet ein PM darüber hinaus weitere Möglichkeiten der Dokumentation in Form eines Wikis zum Beispiel, welches eigenständig erstellt werden kann, allerdings auch selbstverantwortlich gepflegt werden muss. Ähnlich dem Subversion Repository kann auch hier eine personalisierte Entstehungshistorie nachvollzogen werden. Ein späteres Projekt, das die Arbeit eines Digitalen Editionsprojekts rekonstruieren will, sollte immer von einer gewissen Lückenhaftigkeit der Daten eines Projektmanagement-Systems ausgehen.<!--<note xml:id="beethoven-ftn10" n="10">Von den verschiedenen Detmolder Projekten nutzt lediglich eines Redmine durchgängig in konsistenter Weise; bei allen anderen Projekten wird bzw. wurde dieses System nur temporär bzw. nur für Teile der anfallenden Arbeiten genutzt.</note>--> 
               </p>
               <p>Trotz der Gefahr einer mangelhaften Dokumentation der Daten bildet die Kombination der Aufzeichnungen im SVN und PM grundsätzlich eine solide Quellengrundlage. Das nun bereits 18&#x00A0;Monate alte Projekt <hi rend="italic">Beethovens Werkstatt</hi> bedient sich des PM’s in ambitionierter Weise, indem wöchentliche Besprechungen und aktuelle Arbeitsstände sowie Zeitpläne und Übersichten zu Modulplanungen protokolliert sowie das Ticketsystem genutzt werden.</p>
            </div>
            <div xml:id="beethoven-div06">
               <head>Terminologisches und Methodik</head>
               <p>Neben der praktischen Gestaltung der editorischen Arbeit ist für ein späteres Projekt vor allem aber auch die methodische Ausrichtung der Edition, also die zugrundeliegende Forschungsfrage von Interesse. Was wollte die Edition erreichen? Wie motiviert sich die Auswahl der berücksichtigten Quellen? An wen richtet sich die Ausgabe und welche Nutzung lässt sie &#x2013; vielleicht ganz bewusst &#x2013; außer Acht? Gibt es einen oder mehrere edierte Texte und nach welchen Kriterien wird er bzw. werden sie erstellt?</p>
               <p>Der Wert einer aktiven Beantwortung dieser Fragen auch innerhalb einer Digitalen Edition versteht sich von selbst und sollte genauso, wie eine gedruckte Ausgabe im (General-)Vorwort Auskunft über ihre Zielsetzung und Methodik gibt, wahrgenommen werden können. Allerdings, und hier findet sich ein zentraler Unterschied, sind Digitale Editionen noch immer methodisches Neuland &#x2013; viele Ausgaben versuchen gezielt, die Grenzen der veränderten medialen Umgebung neu auszuloten und über das Technische hinaus auch inhaltlich-methodisch neue Impulse zu setzen. Trotz der Verbreitung Edirom-basierter Ausgaben<note xml:id="beethoven-ftn11" n="11">Vgl. <ptr target="http://www.edirom.de"/>. Obwohl ein nennenswerter Anteil der aktuellen Digitalen Editionen auf dieser Software aufsetzt (u.&#8239;a. Reger-Werke-Ausgabe, OPERA u.&#8239;a.), handelt es sich dabei gerade nicht um die Avantgarde. Diese findet in Einzelprojekten wie <hi rend="italic">Beethovens Werkstatt</hi> oder <hi rend="italic">Freischütz Digital</hi> statt, deren Erkenntnisse und technischen Errungenschaften nach und nach in Edirom und von dort in die Breite der sie einsetzenden Projekte zurückfließen können.</note> 
                  hat sich bislang kein Standard Digitaler Editionen etablieren können und angesichts der Dynamik der Entwicklungen in diesem Bereich ist eine Normierung in den nächsten Jahren bedauerlicherweise auch nicht zu erwarten. Grundsätzlich kann man gerade in dieser Situation davon ausgehen, dass die beteiligten Wissenschaftler den öffentlichen Diskurs suchen und ihre Überlegungen auf einschlägigen Tagungen wie der Music Encoding Conference, der DHd oder auch der DH bzw. in entsprechenden Publikationen vorstellen. Dabei lässt sich ein generelles Abzielen auf Etablierung von Standards beobachten, welches jedoch ein kontinuierlicher Vorgang des Entwickelns, Revidierens und Erkennens bleibt. Die Kurzlebigkeit von Erkenntnissen innerhalb eines dynamischen Prozesses spielt aber unter Umständen eine erhebliche Rolle, welche unbedingt beachtet werden sollte: Bestimmte Hypothesen, auf denen ein Editionsprojekt aufsetzt, können sich im Verlauf der Arbeit als falsch oder wenig zielführend erweisen, dementsprechend Annahmen revidiert und Zielsetzungen geändert werden. Bei den gegenwärtigen Digitalen Editionen handelt es sich i.&#8239;d.&#8239;R. um methodische Grundlagenforschung, entsprechend offen muss sich der Projektverlauf gestalten (dürfen).<note xml:id="beethoven-ftn12" n="12">So hat sich u.&#8239;a. im Rahmen des Projekts <hi rend="italic">Freischütz Digital</hi> gezeigt, dass der Aufwand zur gleichzeitigen Erhöhung von Quantität und Komplexität der genutzten Codierungen wesentlich unterschätzt wurde. Da es aber keine Vorerfahrungen durch andere, ähnlich gelagerte Projekte gibt, handelt es sich hierbei um ein legitimes Projektergebnis &#x2013; das allerdings anders aussieht, als zu Beginn erwartet.</note></p>
               <p>Ein wesentliches Charakteristikum von Grundlagenforschung ist auch ihre terminologische Entwicklung. Gerade in dieser Hinsicht ist <hi rend="italic">Beethovens Werkstatt</hi> zu erwähnen. Das Projekt versucht, genetische Textkritik im digitalen Medium umzusetzen. Da es für eine solche Editionsform im Bereich Musik – auch in Papierform – keine Vorlage gibt, erfordert dies nicht zuletzt eine grundlegende Auseinandersetzung mit der Terminologie, die u.&#8239;a. aufgrund des anderen Textbegriffs nicht ohne Weiteres aus der Literaturwissenschaft übernommen werden kann. Diese sehr zeitintensive Auseinandersetzung mit terminologischen Fragestellungen findet &#x2013; neben etlichen persönlichen Besprechungen &#x2013; vor allem in einem Wiki-System<note xml:id="beethoven-ftn13" n="13">Vgl. <ptr target="https://de.wikipedia.org/wiki/Wiki"/>. Es handelt sich um ein Internet-basiertes System, bei dem alle (registrierten) Benutzer Webseiten nicht nur lesen, sondern auch bearbeiten können.</note> 
                  statt, wobei in diesem Fall ein in Redmine (s.&#8239;o.) zur Verfügung stehendes Modul genutzt wird. In diesem Wiki werden die einzelnen Begriffe auf je eigenen Seiten definiert und diese Definitionen dann kontinuierlich revidiert, bis eine hinreichend stabile Fassung gefunden ist, die als zur Veröffentlichung geeignet angesehen wird; diese Fassung wird auf der Webseite des Projekts zugänglich gemacht und damit für einen breiteren Diskurs <q>geöffnet</q>. Somit ist die Entwicklung des jeweiligen Begriffs ab diesem Zeitpunkt öffentlich nachvollziehbar. 
                  Aber auch die früheren, internen Versionen lassen sich in allen Zwischenschritten innerhalb des Wikis rekonstruieren<!--, wobei der jeweilige Bearbeiter genannt wird-->. </p>
               <pb/>
               <p>Abgesehen von den eingeschränkten Formatierungs- und Kommentarfunktionen des Wikis erweist sich <!--eine präzise Rekonstruktion,--> aber vor allem die Mischung aus on- und offline-Diskussionen als problematisch: Zwar können die einzelnen Textstadien verfolgt werden, der projektinterne Austausch über diese Begriffe, der zu den entsprechenden Revisionen führt, findet aber nur teilweise im Digitalen statt, so dass ggf. nicht alle Argumente nachvollzogen werden können. Bei aller Datenfülle, der sich ein nachnutzendes Projekt gegenübersieht, bleibt damit das traditionelle editorische Problem, mit einer nicht vollständigen Liste von (Text-)Zeugen arbeiten zu müssen: Nur das, was in Niederschriften bzw. hier: Daten überliefert ist, kann sicher identifiziert werden, mögliche Lücken im (digitalen) Gedächtnis müssen dagegen durch Interpolation, Interpretation und Divination gefüllt werden. Dieses Problem gilt allerdings nicht allein für die in einem Projekt entwickelte Terminologie, sondern im Grunde für alle konzeptionellen Inhalte &#x2013; im Idealfall bilden die Dokumentation und Glossare den tatsächlichen Gebrauch von Terminologie und Konzepten korrekt ab, in der Praxis aber hinken sie oft der inhaltlichen Entwicklung hinterher oder postulieren ein im Projekt (zu diesem Zeitpunkt) oft noch nicht erreichtes Ideal. Grundsätzlich ist der Zusammenhang von Dokumentation und Projektdaten also als lose zu betrachten, auch wenn Inkonsistenzen nicht auf den ersten Blick ersichtlich werden. </p>
            </div>
            <div xml:id="beethoven-div07">
               <head>Codierungsrichtlinien</head>
               <p>Als besonders problematisch erweisen sich diese Inkonsistenzen bei der Dokumentation der TEI- und MEI-Codierungen; Abweichungen zwischen Dokumentation und Datengebrauch können hier zu Fehlinterpretationen der Daten führen. Für eine angemessene Umsetzung erfordern Digitale Editionen daher Codierungsrichtlinien, die in ihrer Funktion weitgehend den traditionellen Editionsrichtlinien entsprechen. Sie gehen inhaltlich weit über deren technische Festlegungen etwa zur Typografie hinaus und bilden die gesamte informationstechnische Modellierung des editorischen Sachverhalts ab, d.&#8239;h. sie legen fest, welche Bedeutung einzelnen Aspekten beigemessen werden soll, in welcher Granularität sie erfasst werden und in welcher Weise sie auch für spätere Forschung noch zur Verfügung stehen. Sie legen damit nicht nur den technischen Rahmen, sondern auch die inhaltlichen Möglichkeiten der Edition fest. Allerdings unterliegen sie &#x2013; wie auch die Editionsrichtlinien einer gedruckten Ausgabe &#x2013; während der Projektlaufzeit einem kontinuierlichen Wandel, der im Wesentlichen auf die jeweils gemachten Erfahrungen und konzeptionelle Verfeinerungen zurückzuführen ist. </p>
               <pb/>
               <p>Die beste Möglichkeit, solchen Inkonsistenzen vorzubeugen, ist der konsequente Einsatz von ODD.<note xml:id="beethoven-ftn14" n="14"><q>One Document Does it all</q> (<ptr target="http://wiki.tei-c.org/index.php/ODD"/>).</note> Mit dieser Schemasprache lassen sich die Datenformate TEI und MEI für ihren jeweils projektspezifischen Einsatzzweck anpassen, so dass nur die in der Edition benötigten und zu nutzenden Funktionen zur Verfügung stehen.<note xml:id="beethoven-ftn15" n="15">So hat z.&#8239;B. die Entscheidung, ob Vorzeichen als eigenständiges Objekt oder als Parameter einer Note erfasst werden sollen, Auswirkungen auf die mögliche Präzision in der Erfassung von Abweichungen zwischen mehreren Quellen. Auch die Möglichkeit, Akzidentien als Eintragungen von fremder Hand zu identifizieren, wird dadurch beeinflusst.</note> 
                  Der wesentliche konzeptionelle Vorteil von ODD ist dabei, dass aus der gleichen Datei sowohl ein zur Validierung der Projektdaten geeignetes Schema als auch eine inhaltlich entsprechende Dokumentation gewonnen werden kann. Damit lassen sich Inkonsistenzen zwischen Daten und Dokumentation wirksam vermeiden. Allerdings sollten im Idealfall in einer solchen ODD-Datei auch die Beschreibungen einzelner Elemente (wo nötig) an den projektspezifischen Gebrauch angepasst werden, um absolute Klarheit über ihren Gebrauch zu schaffen. Allzu oft reduziert sich der Gebrauch von ODD auf die technische Beschränkung der Format-Möglichkeiten, ohne jedoch die inhaltlichen Beschreibungsmöglichkeiten in angemessener Weise umzusetzen.<note xml:id="beethoven-ftn16" n="16">Dies betrifft u.&#8239;a. das Projekt <hi rend="italic">Beethovens Werkstatt</hi>. Die dort genutzte ODD-Datei ist zwar öffentlich verfügbar (vgl. <ptr target="https://github.com/BeethovensWerkstatt/Data-Model"/>), dokumentiert aber bislang kaum den tatsächlichen Gebrauch der weiterhin vielfältigen Möglichkeiten. Dies wird u.&#8239;a. daraus ersichtlich, dass die beiden ersten in diesem Projekt erarbeiteten Beispiel-Editionen trotz eines &#x2013; wenn auch nur leicht &#x2013; veränderten Datenmodells auf die gleiche, unveränderte ODD-Datei zurückgreifen.</note> 
                  Ein Grund für diesen Missstand mag sein, dass die Validierung der Daten eine sofortige Kontrollmöglichkeit für die eigene Arbeit bietet, während eine Dokumentation i.&#8239;d.&#8239;R. nicht in ähnlicher Weise unmittelbar nach innen wirken kann. Gerade um die Nutzbarkeit der erstellten Daten über den Abschluss der Edition hinaus sicherstellen zu können, ist es aber überaus wichtig, die eigenen Codierungsrichtlinien sauber in ODD abzubilden. </p>
            </div>
            <div xml:id="beethoven-div08">
               <head>Jenseits der Daten</head>
               <p>Eine gründliche und aktuelle Dokumentation der Daten bietet damit gute Voraussetzungen zur späteren Rekonstruktion und Nachnutzung der Editionsinhalte. Allerdings bestehen Digitale Editionen nicht nur aus Daten, sondern auch aus den Anwendungen, die diese Daten visualisieren und einem Benutzer zugänglich machen. Um eine Digitale Edition vollständig rekonstruieren zu können, muss daher auch die zugehörige Software berücksichtigt werden. Während die Daten durch den überwiegenden Gebrauch XML-basierter und grundsätzlich gut dokumentierter Formate wie zum Beispiel MEI und TEI als recht <q>zukunftsfähig</q> anzusehen sind, gilt dies nicht automatisch in gleicher Weise für die Anwendung(en), welche die Daten einer Ausgabe erst nutzbar machen. Es werden häufig Programmiersprachen und -konzepte verwendet, deren langfristige Verfügbarkeit angesichts der gegenwärtigen technischen Entwicklungsgeschwindigkeit zumindest nicht ohne Weiteres garantiert werden kann. Ob eine Digitale Edition nach einer längeren Zeit also so rekonstruiert werden kann, wie sie zum Zeitpunkt ihrer ersten Veröffentlichung dargestellt wurde, ist aus heutiger Perspektive schwer zu beurteilen. Die beste Strategie eines Editionsprojekts ist in dieser Hinsicht sicherlich der Einsatz von Open-Source-Software, die &#x2013; ebenso wie die Daten &#x2013; möglichst ausführlich zu dokumentieren ist. Damit kann ggf. auch die Benutzeroberfläche der Edition rekonstruiert werden. Sinnvoller wäre allerdings, wenn bereits heute eine engere Zusammenarbeit zwischen Editionsprojekten und Bibliotheken gesucht würde, um deren Expertise bei der Archivierung zu nutzen und sie zugleich frühzeitig, d.&#8239;h. vor Ablauf der Projekte in die Vorbereitung einer möglichst langen Haltbarkeit (nicht nur der Daten) einzubeziehen. </p>
            </div>
            <div xml:id="beethoven-div09">
               <head>Fazit</head>
               <p>Bedenkt man die verschiedenen <q>Spuren</q>, die digitale Editionsprojekte hinterlassen, so erscheint es zunächst durchaus realistisch, dass der <q>Verwertungsgrad</q> der editorischen Arbeit in der publizierten Ausgabe wesentlich höher liegt, als dies mit gedruckten Ausgaben praktikabel wäre. Infolgedessen dürfte es für spätere Editionsprojekte deutlich leichter sein, auf frühere (digitale) Editionen aufzubauen und diese weiter anzureichern. Goldene Zeiten werden aus diesen Gründen aber noch nicht anbrechen: Zunächst kann keine Vorarbeit die eigene Auseinandersetzung mit den zur Verfügung stehenden Primärquellen ersetzen. Darüber hinaus musste in vielen bisherigen digitalen Editionsprojekten die Fülle an Informationsquellen mitunter als problematisch erfahren werden &#x2013; dann nämlich, wenn bei der Auswertung dieser Informationen der mögliche Erkenntnisgewinn den dafür nötigen Zeitaufwand nicht mehr rechtfertigt. Leider erscheint es kaum möglich, dieses Verhältnis im Vorfeld abzuschätzen. Letztlich entspricht diese Situation also jeder editorischen Arbeit, die bei vielen verfügbaren Zeugen zwar breitere Erkenntnisse zutage fördern kann, gleichzeitig aber auch erheblich mehr Zeit zur Rekonstruktion der Daten benötigt, als für deren Erstellung nötig war. </p>
               <p>Um dieser Situation entgegenzuwirken, ist die konsequente, zeitnahe und umfassende Dokumentation aller editorischen Arbeiten unerlässlich, welche zu großen Teilen mit dem Anspruch einer sehr konsistenten und zielorientierten Arbeitsweise einhergeht. Dies beinhaltet die inhaltliche Konzeption, die im Projekt genutzte Terminologie, die erarbeiteten Codierungsrichtlinien sowie die darauf basierenden Editionsdaten, die für ihre Erstellung und Publikation eingesetzte Software, sowie letztlich auch den Projektverlauf selbst (um den weiteren Kontext für die Interpretation der anderen Daten zu liefern). All diese Aspekte mit der nötigen Sorgfalt zu dokumentieren erfordert Zeit in nicht unerheblichem Maße &#x2013; Zeit, die den meisten heutigen Editionsprojekten fehlt. 
                  Allerdings können nur auf diese Weise ausreichend gute <q>Spuren</q> gelegt werden, die die Nachhaltigkeit Digitaler Editionen sicherstellen. Es sollte im gemeinsamen Interesse von Editionsprojekten und Forschungsförderern liegen, die entsprechenden Kapazitäten bei der Planung und Erstellung von Ausgaben einzuplanen.</p>
               <figure xml:id="beethoven-fig01" place="here">
                  <graphic url="figures/beethoven-fig01.png" width="1512px" height="1045px"/>
                  <head type="legend"/>
               </figure>
               <!--<p>P.S: (machen wir handschriftlich, also wird eine Abbildung)</p>
               <p>Lieber Joachim,</p>
               <p>Spurensuche bzw. Spurenlegen kann durchaus eine bisher noch nicht genannte, jedoch hier deutlich sichtbare Ausprägung haben…. </p>
               <p>Dieser Beitrag zur Festschrift wurde stellvertretend für das Projekt Beethovens Werkstatt von Maja Hartwig und Johannes Kepper verfasst, während der Rest des Teams durch redaktionelle Um-Schreibungen in Tinte (Elisa Novara), Erzeugung von weiteren Textvarianten mit Bleistift (Richard Sänger), Anmerkungen mit Rötel (Federica Rovelli), Korrekturen und Ergänzungen (Susanne Cox) einen kleinen Teil zur Verfertigung desselben beitrug. Alle Werkstättler gratulieren Ihnen von Herzen und wünschen Ihnen anlässlich Ihres 60.&#8239;Geburtstages alles erdenklich Gute. Abschließend eine kleine editorische Weisheit, die Sie auf all’ Ihren Wegen immer bedenken mögen: <q>Ergänzung ist Teufelswerk</q>. [noch nicht fertig…]</p>-->
            </div>
      </body>
      <back>
         <div type="bibliography">
            <listBibl>
               <bibl xml:id="Kepper2009">Johannes Kepper, <title level="m">Musikedition im Zeichen neuer Medien</title>, Norderstedt 2009</bibl>
               <bibl xml:id="Tomasello1999">Michael Tomasello, <title level="m">The Cultural Origins of Human Cognition</title>, Cambridge 1999</bibl>
               <bibl xml:id="Eibl2003">Karl Eibl, <title level="a">Vergegenständlichung. Über die kulturstiftende Leistung der Menschensprache</title>, in: <title level="m">Regeln der Bedeutung. Zur Theorie der Bedeutung literarischer Texte</title>, hg. von Fotis Jannidis, Gerhard Lauer, Matías Martínez und Simone Winko, Berlin u.&#8239;a. 2003, S.&#8239;566&#x2013;590</bibl>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
