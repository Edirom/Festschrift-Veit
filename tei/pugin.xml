<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="../schemata/cgrid.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="../schemata/cgrid.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main">Interaction with Music Encoding</title>
            <author>
               <name><forename>Laurent</forename> <surname>Pugin</surname></name>
               <affiliation>has a background in musicology and computer science, with research fields in human sciences (philology, music notation, bibliography) and technology (image processing, machine learning). He was postdoctoral researcher and lecturer at McGill University and visiting scholar at Stanford University. He is the lead developer of an open source software application, Aruspix, and is involved in a digital edition project on Luca Marenzio. He is co-director of the Swiss RISM Office in Bern and secretary of the RISM Board. He is member of the Board of the <hi rend="italic">Music Encoding Initiative</hi> (MEI) and co-chair of its technical team.</affiliation>
               <email/>
            </author>
         </titleStmt>
         <publicationStmt>
            <publisher>Virtueller Forschungsverbund Edirom (ViFE)</publisher>
            <availability>
               <licence target="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License (CC BY 4.0)</licence>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>Converted from a Word document</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <langUsage>
            <language ident="en"/>
         </langUsage>
         <particDesc>
            <listPerson>
               <person xml:id="pugin-pers001">
                  <p>Good, Michael</p>
               </person>
               <person xml:id="pugin-pers002">
                  <p>Lee, Sang Won</p>
               </person>
               <person xml:id="pugin-pers003">
                  <p>Roland, Perry</p>
               </person>
               <person xml:id="pugin-pers004">
                  <p>Selfridge-Field, Eleanor</p>
               </person>
            </listPerson>
         </particDesc>
      </profileDesc>
      <encodingDesc>
         <tagsDecl>
            <rendition xml:id="pugin-latex-width06">width=.6\textwidth</rendition>
         </tagsDecl>
      </encodingDesc>
      <revisionDesc>
         <change when="2015-12-03T09:13:00"
         who="https://github.com/peterstadler">Korrekturen des Autors eingearbeitet.</change>
         <change when="2015-11-18T14:37:01.186+01:00"
            who="https://github.com/peterstadler">Initial transformation from OxGarage TEI P5 to jTEI customization.</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div type="abstract" xml:id="pugin-abstract"><p>Western music tradition is primarily written and music has been brought to us mostly through manuscripts and printed sources. Over recent decades, several computer music engraving tools have been developed, targeting mostly printed output and mimicking plate engraving. However, online technologies and new devices that have recently emerged offer new ways of envisaging music publishing. In this context, the <hi rend="italic">Music Encoding Initiative</hi> (MEI) plays a key role, in particular for critical digital music editions. This paper investigates the development of interaction possibilities for MEI digital critical editions based on a newly developed computer rendering library named Verovio.</p></div>
      </front>
      <body>
         <div xml:id="pugin-div01">
            <head/>
            <p>A significant proportion of Western music is part of a written tradition and its history is closely linked to that of music notation. Over the centuries, written music notation has served as a medium for composers that allows them to interact with musicians, conductors, singers or instrument performers. One key characteristic of music notation is that it is an open system that was constantly evolving, and continues to evolve, according to the needs and original ideas of composers. This is true for the introduction of the most fundamental components of music notation, such as staff lines or notes, but also for the most atypical and peculiar additions, as seen in particular for twentieth and twenty-first century repertoires. New symbols, but principally new ways of arranging and assembling them, are constantly added and established. In this regard, music notation is quite different from text, whose evolution consists mostly of changes in the vocabulary and grammar of the language not requiring significant changes in the components used to write it. These are more or less limited to the letters of the alphabet, and this has not significantly changed for centuries.</p>
            <p>The medium used for writing music notation has also evolved over the centuries. As for text, printing followed on from handwritten parchment and paper manuscripts. Music was initially printed with a multiple impression technique, and later with a single impression typographic technique that was particularly well suited to vocal music. During the eighteenth century, engraving gradually superseded the typographic printing technique that the evolution of music notation was making less and less appropriate. This was due in part to the many changes to notation brought on by the development of idiomatic instrumental music, with shorter note durations, larger ambitus, and the development of dynamics and articulation signs, for example. The introduction of a new technique does not automatically make previous ones obsolete. Handwritten manuscripts are still used today, and the typographic printing technique remained in used for decades after engraving became the norm. The successful introduction of a new technique is often determined by economic factors and its profitability. The single impression technique made music printing much simpler and more profitable than before, which was decisive for developing a new marking. Conversely, early attempts at music engraving in the sixteenth century remained largely unexploited for a long time even though the technique was clearly much more appropriate than typography for music. Later, at the end of the eighteenth century, lithography rapidly became a widely used printing technique, being four times cheaper than engraving.<ref target="#Rasch2005" xml:id="pugin-ftn1" type="bibl"/>
            </p>
            <p>Repeatedly throughout history we see attempts to make one technique resemble another, usually in imitation of a more prestigious or more established one. For example, the first music incunabula were made to look very similar to manuscripts, as were early engraved prints. Likewise, in eighteenth century typography, square note heads from sixteenth and seventeenth century prints were replaced by round ones, undoubtedly to imitate the appearance of engraved prints.</p>
            <p>Imitation is just as much a driving force in computer music engraving. Since the beginning of the development of music notation software applications in the Sixties, the goal has been primarily to generate a result that mirrors plate engraving. Music engraving has a long tradition, with its own rules, and can be seen as an art in itself.<note xml:id="pugin-ftn2" n="2">For an overview of music engraving (and music printing in general) as a visual art, see <ref target="#VanOrden2001" type="bibl"/></note> 
               Creating a music engraving software application requires both this tradition and the rules of engraving to be understood and formalized. The numerous writings on music engraving have served as guidelines for the development of music notation software applications.<note xml:id="pugin-ftn3" n="3"><ref target="#Ross1987" type="bibl"/>; more recently <ref target="#Gould2011" type="bibl"/></note> 
               However, the inherent complexity of music notation, when combined with the desire to imitate engraving which is of a non-written tradition, makes computer engraving a complex endeavour. It remains barely conceivable that perfect digital engraving can be obtained without human intervention.<ref target="#Powell2007" type="bibl" xml:id="pugin-ftn4" n="4"/>
            </p>
            <p>Music engraving software applications have also tried to imitate plate engraving in terms of output media by targeting printed editions. The available output of music notation software applications is traditionally PostScript or PDF, two printing formats developed by Adobe. This situation is not surprising since most of the major tools that are currently used, such as Score, Finale or Sibelius, to mention only a few, were designed before the appearance or the growth of the internet.<note xml:id="pugin-ftn5" n="5">See <ref target="#Hewlett1986" type="bibl"/> for a review of the numerous early systems in computer music printing.</note>
               At the other end of the chain, paper is undoubtedly still the most widely used support for musicians to read music, making printed output fully appropriate. However, only twenty or thirty years after the initial development of music notation software applications, the digital domain has significantly changed with the advent of the online world. For music notation, this translates into new possibilities but also new challenges to be faced. While PDF can easily be published online, either as is or converted to images, it is not a very flexible format and remains seriously limited in terms of interaction. </p>
         </div>
         <div xml:id="pugin-div02">
            <head>Behind the scenes</head>
            <p>A great number of codes for music have been developed over the years. We can group them into three categories, along the lines of <name ref="#pugin-pers004">Selfridge-Field&#x2019;s</name> survey: codes for sound applications, codes for music notation applications, and codes for analytical and more abstract applications.<ref target="#SelfridgeField1997" type="bibl" xml:id="pugin-ftn6" n="6"/>
               For notation, many of the codes were designed as a storage facility for software applications. This is certainly the case for the proprietary binary formats, which are not human readable and, for the most part, not openly documented. This makes data exchange extremely difficult, if not impossible. A file generated by one software application cannot be read by another, nor even sometimes by later versions of itself when backward compatibility is not supported. A first attempt at providing an exchange data format for music notation software applications was made in the mid-Nineties with the <hi rend="italic">Notation Interchange File Format</hi> (NIFF). For various reasons, however, NIFF was eventually abandoned and the currently most widely used interchange format for music notation remains MusicXML.<note xml:id="pugin-ftn7" n="7"><ptr target="http://www.musicxml.com"/></note>
            </p>
            <p>MusicXML started as an XML representation of MuseData. It was developed by <name ref="#pugin-pers001">Michael Good</name> and is now owned by MakeMusic, the company that develops Finale. One advantage of MusicXML over NIFF was not being binary, making it human readable. Because it uses XML as the underlying data structure, it also has the advantage of being processable with XML-related technologies, such as XSL transforms, even though in practice this does not seem to be a widely used approach.</p>
            <p>Another important plain text format for music notation is LilyPond.<note xml:id="pugin-ftn8" n="8"><ref target="#Nienhuys2003" type="bibl"></ref>. See also <ptr target="http://www.lilypond.org"/></note> 
               More than a code, LilyPond is in fact a compiler for typesetting music notation. The code used by the LilyPond compiler is very similar to the one used by the LaTeX typesetting system, with a markup based on escaped commands and bracketed parameters. LilyPond is a quite powerful system that can typeset complex scores. Among its strengths is the fact that it has a modular design and that it is extendable. One key concept with LilyPond is that the score is defined with text markup that is eventually processed and transformed into music notation. This differs from so-called WYSIWYG (<soCalled>what you see is what you get</soCalled>) approaches adopted by most of the notation software applications, where the score is created through a user-interface that directly shows what the final output of the score looks like.</p>
            <p>The MusicXML and LilyPond codes are taken here as counter examples for illustrating the objective pursued by the <hi rend="italic">Music Encoding Initiative</hi> (MEI).<note xml:id="pugin-ftn9" n="9">The project was started about 15&#x00A0;years ago by <name ref="#pugin-pers003">Perry Roland</name> and is now developed by a community of scholars with a variety of backgrounds, expertise areas and interests. See <ptr target="http://www.music-encoding.org"/></note> 
               The overall goal of MEI is to define a structure for encoding musical documents. It focuses on formalizing the interpreted content of music documents in a declarative way (as opposed to a procedural way). As a result, one of the principal goals of MEI is not how to encode the music notation for it to be processable by existing computer software applications, or for it to be typesetted, but instead how to model the music notation and how to represent it digitally in a structured and meaningful way. This fundamental difference in the approach can be corroborated by the fact that for many years, MEI remained designed away from software application support, keeping it abstract and un-biased by any software application requirement. For MEI, however, this resulted in a low rate of adoption for several years since it was present primarily at a theoretical level. Furthermore, community-based developments require in-depth discussions, which can sometimes slow down the development process. This was certainly the case with MEI, but undoubtedly in a beneficial way. The situation has changed radically over the last few years and MEI is now widely used in research projects throughout the world.</p>
            <p>The aforementioned codes, and many others, share similar basic concepts (e.&#8239;g., staff, notes, rests, etc.). This means that, in practice, converting from one of these formats to another is possible, but only to some extent. It is in fact quite difficult to go beyond the basic similar concepts, and this is where the fundamental differences between the encoding approaches have an impact. LilyPond is notoriously difficult to parse outside the LilyPond compiler when it comes to complex scores. One reason is that it uses its own markup syntax (not XML) and a parser that is embedded in the LilyPond compiler, which makes converting a LilyPond file extremely difficult. But the main reason is that the structure of a LilyPond file is always organized according to the desired typeset output, with a strong focus on layout. Consequently, even though LilyPond uses an architecture that separates the data from the desired output, the latter fundamentally drives the structure of the data. Furthermore, because the structure is not constrained by any schema, it can be of unpredictable complexity. With MusicXML, even though like MEI it uses XML and is defined by a schema, the stumbling block is structural, too. Some parts of MusicXML clearly do not model music notation but are instead structured based on how a software application processes the data. In other words, it is highly procedural, and the structure of the notation is not given explicitly but can be extracted only by sequentially processing the data. This is true for chords or multiple voice writing (where the processing <soCalled>cursor</soCalled> goes backward or forward), all common components of music notation for which the representation in MusicXML is clearly problematic, beyond its interchange role.</p>
            <p>Nonetheless, converting MEI to other codes for rendering the notation has been an acceptable solution for the MEI community for several years and in many projects. For this the community has developed various conversion stylesheets, allowing the MEI to be converted directly to a typesetting format, or to be imported into other software applications via MusicXML.<note xml:id="pugin-ftn10" n="10"><ptr target="https://github.com/music-encoding/encoding-tools"/></note> 
               Such a situation was not fully satisfactory, however, for two main reasons. The first is that converting for rendering quickly becomes problematic with the rich and complex MEI markup that is precisely its unique attribute. With a conversion step, it is likely that not all the information will be preserved in the rendering, or at least only in cumbersome ways. The second reason, which is directly related to the first, is that converting for rendering seriously limits the potential for interaction, because some features might be inappropriately rendered. Furthermore, having a chain of tools makes it difficult to go back from the notation to the encoding.</p>
         </div>
         <div xml:id="pigin-div03">
            <head>Interaction</head>
            <p>Music notation interaction is already quite prevalent in music performance and music composition environments.<ref target="#Freeman2010" type="bibl" xml:id="pugin-ftn11" n="11"/>
               In many cases, notation is mixed with various types of digital objects, creating so-called augmented multi-media scores. In such approaches, the score is treated as a graphic object allowing a temporal object to be represented and extended. One example of such an environment is InScore, a framework for designing interactive and augmented live music scores.<ref type="bibl" target="#Fober2012" xml:id="pugin-ftn12" n="12"/>
               It reads common Western music notation (e.&#8239;g., MusicXML) and can be extended with arbitrary digital material, such as images, vector graphics, or videos, for example. It is highly performance focused, with an interface to the <hi rend="italic">Open Sound Control</hi> (OSC) format. In such environments, real-time processing is often a key requirement. In <name ref="#pugin-pers002">Lee</name>, the music notation is displayed in real time, which makes it possible for acoustic musicians to be integrated into laptop ensembles.<ref target="#WonLee2013" type="bibl" xml:id="pugin-ftn13" n="13"/>
               Other projects have proposed solutions for integrating uncommon dynamic music notations in Max/MSP environments.<ref type="bibl" target="#Hajdu2015" xml:id="pugin-ftn14" n="14"/>
               LilyPond, too, has been used for real-time generation of music notation.<ref target="#Baird2005" type="bibl" xml:id="pugin-ftn15" n="15"/>
            </p>
            <p>Applications that involve interactions and that are widely used by musicologists are music notation editors. They are mostly desktop applications, with their own music notation rendering engine directly embedded in them. A few online music notation editors exist, however. One of them is Scorio, which uses LilyPond running as a server backend.<note xml:id="pugin-ftn16" n="16"><ptr target="http://www.scorio.com"/></note>
               Noteflight is an additional example of such an application.<note xml:id="pugin-ftn17" n="17"><ptr target="http://www.noteflight.com"/></note> 
               Originally written in Adobe Flash it now also offers an HTML5 version. Interaction with music notation is frequent in <hi rend="italic">music information retrieval</hi> (MIR) applications, as well. For example, basic interaction can be necessary for highlighting search results, or in score-following applications. In these, the rendering of the music notation is usually achieved through rendering libraries and the interaction is most of the time unidirectional.</p>
            <p>In 2013, the Swiss RISM Office launched the development of an open source software library for rendering music incipits, named Verovio.<note xml:id="pugin-ftn18" n="18"><ref target="#Pugin2014" type="bibl"/>. See also <ptr target="http://www.verovio.org"/></note> 
               The main idea was to develop a tool that could render MEI natively. That is, without having MEI converted to another format, either explicitly or internally in the software application used for rendering. With Verovio, the MEI markup is parsed and rendered as notation with a single tool and in one step. Verovio has been developed as a software library and not as a full software application. This means that it is not a desktop music notation application but instead a software component that can be integrated into a wide range of application environments. </p>
            <p>The decision was made to develop Verovio from scratch in order to be able to operate on an in-memory representation of MEI. Verovio directly implements the MEI structure internally, with the exception of a top-level page-based organization that is required for the organization of the rendering.<ref type="bibl" target="#Pugin2014" xml:id="pugin-ftn19" n="19"/>
               The reason for choosing to implement a library from scratch rather than modifying an existing library such as GuidoLib,<ref target="#Daudin2009" type="bibl" xml:id="pugin-ftn20" n="20"/>
               for example, is that in the long run it will make it significantly easier to render complex MEI features. Previous experience has indeed shown that modifying an existing solution can be very quick to develop at the beginning, but that the development curve eventually reaches a plateau. </p>
            <p>Verovio is designed to be light and fast and has no external dependencies, making it very flexible and easy to embed. This opens up a whole range of different possible uses. The JavaScript version of Verovio is particularly promising because it provides a fast in-browser music MEI typesetting engine that can easily be integrated into web-based applications. This setup makes it possible to design groundbreaking web applications where the MEI encoding is rendered on the fly. In such designs we can rethink the interface and avoid mimicking page output. We can instead adjust the layout dynamically to the screen of the device used by the user. The layout can be calculated to fill the size of the screen, or interactively changed according to a zoom level adjusted by the user.</p>
            <p>However innovative the dynamic layout of music notation may be, it remains a very basic interaction. Verovio aims to go further and to produce a graphic output that can then be the foundation for more complex interaction. The output in Verovio is designed in an abstract way. This means different output formats can easily be implemented. The default format chosen is the <hi rend="italic">Scalable Vector Graphics</hi> (SVG) format. SVG is an XML vector graphic format developed by the W3C.<note xml:id="pugin-ftn21" n="21"><ptr target="http://www.w3.org/Graphics/SVG/"/></note>
             It is supported natively by all modern browsers, including on mobile devices. One interesting feature of SVG is that its XML tree can be constructed as desired. Since Verovio implements the MEI structure internally, this key feature of SVG makes it possible to preserve the MEI structure in the output. Each element in the MEI document has a corresponding <gi>g</gi> SVG element in the SVG tree with the relevant <att>xml:id</att> and <att>class</att> attributes. For example, a <gi>note</gi> element with an <att>xml:id</att> attribute in the MEI file will have a corresponding <gi>g</gi> element in the SVG with a <att>class</att> attribute equal to <q>note</q> and an <att>id</att> attribute corresponding to the <att>xml:id</att> of the MEI note. </p>
            <pb/>
            <p>Preserving the MEI structure in the SVG output is a considerable overhead in the rendering process, since the order in which elements can be drawn does not always correspond to the encoding structure.<note xml:id="pugin-ftn22" n="22">For example, drawing the duration bars of a beam is possible only once its notes have been drawn, or in cross-staff notation, drawing a note on a lower staff is possible only when this lower staff has been drawn.</note> 
               Nonetheless, Verovio not only establishes a mapping between each MEI element and the corresponding SVG <gi>g</gi> element, it also preserves the hierarchy of the MEI elements in its output. For example, in MEI, a <gi>beam</gi> can be the child element of a <gi>tuplet</gi>, but the opposite is also possible. The hierarchy is fully preserved in the SVG as shown in Figure&#x00A0;<ref target="#pugin-fig01" type="crossref" rend="no"/>.</p>
            <figure xml:id="pugin-fig01">
               <graphic url="figures/pugin-fig01.pdf" width="1200px" height="1832px"/>
               <head type="legend">The MEI hierarchy is preserved in the SVG output</head>
            </figure>
            <p>Other music rendering tools can also produce SVG, and using this format for music notation is not new. It is also available as an output in LilyPond and VexFlow, or used in the HTML5 version of Noteflight. However, to our knowledge, generating an SVG XML tree that reflects the music encoding is completely new. In other tools, the generated SVG is an unstructured, or very loosely structured, set of vector graphic primitives. In LilyPond, for example, SVG is an alternative to Postscript, and the structure of the SVG is a flat list of graphic primitives corresponding to the sequence in which the corresponding PostScript file is normally written.</p>
            <p>The setup provided by Verovio makes interaction with the music notation in web-browsers extremely simple. Interaction is possible with specific MEI elements by accessing them by <att>id</att>. MEI elements can also be accessed by type. For example, it is straightforward to interact with all slur elements rendered in the SVG since each slur in the MEI will have a corresponding <gi>g</gi> SVG element with the <q>slur</q> <att>class</att> attribute. Furthermore, since the element hierarchy is preserved in the MEI-SVG element mapping, interacting with an element provides access to all its children as structured in the MEI. Accessing a beam in the SVG provides access to all its notes, for example. This would not be the case with an SVG organized as a flat list of graphics. In terms of interaction, all the default interaction possibilities provided by SVG are available out of the box. They include selecting, highlighting via CSS, dragging, hiding, etc.</p>
            <p>As a result, Verovio&#x2019;s output in SVG is not the end of an unidirectional rendering process. Quite on the contrary, it should instead be seen as an intermediate layer standing between the MEI encoding and its rendering that can act as the cornerstone for a bi-directional interaction: from the encoding to the notation, but also from the notation to the encoding through the user interface (Figure&#x00A0;<ref target="#pugin-fig02" type="crossref" rend="no"/>). </p>
            <figure xml:id="pugin-fig02" rendition="#pugin-latex-width06">
               <graphic url="figures/pugin-fig02.png" width="3993px" height="1693px"/>
               <head type="legend">The SVG output of Verovio acts as an interaction layer that sits between the notation and the MEI encoding</head>
            </figure>
         </div>
         <pb/>
         <div xml:id="pugin-div04">
            <head>Interaction with the invisible</head>
            <p>A major field of application of MEI is that of digital critical editions. In this context, variants between the different sources need to be identified and represented. Variants in music critical editing are a topic in themselves.<note xml:id="pugin-ftn23" n="23">See <ref target="#Grier1996" type="bibl"/>.</note>
               What to expect varies significantly from one historical period to another, from one repertoire to another, and from one type of source to another, and ultimately each editorial project is unique. Framing variant definitions and variants needs constantly to be re-evaluated on a case-by-case basis, although some common patterns and categories can be established.<note xml:id="pugin-ftn24" n="24">See <ref target="#Appel2005-Pugin" type="bibl"/></note> 
               Recurrent problems in treating variants include defining the scope of a variant, and deciding when a difference between two sources constitutes a variant (or not).</p>
            <p>MEI does not answer these questions, which are beyond our discussion. However, MEI includes a whole set of features for encoding variants, which is one of its strengths.<note xml:id="pugin-ftn25" n="25">For more information about this, see the chapters <q>Critical Apparatus</q> and <q>Editorial Markup</q> of the MEI guidelines at <ptr target="http://music-encoding.org/documentation/2.1.1/chapters/"/></note> 
               It works in a similar way to TEI (<hi rend="italic">Text Encoding Initiative</hi>), using a parallel segmentation method for the encoding of the variants.<note xml:id="pugin-ftn26" n="26">Chapter 12.2.3: <hi rend="italic">The Parallel Segmentation Method</hi>, in: <hi rend="italic">TEI Guidelines</hi>, URL: <ptr target="http://www.tei-c.org/Vault/P5/2.9.1/doc/tei-p5-doc/fr/html/TC.html#TCAPPS"/></note> 
               With parallel segmentation, the encoding stream is divided into several branches whenever the different sources have divergent content, each branch representing one version. The segmentation is represented with an <gi>app</gi> element that contains all variants, each of them being encoded within an <gi>rdg</gi> element (or a <gi>lem</gi> element for a lemma, or base text, if any).<note xml:id="pugin-ftn27" n="27">This works well for non-overlapping variants. For overlapping variants, or variants overlapping with other elements in the MEI tree, alternative solutions are being developed.</note>
            </p>
            <p>This way of representing variants directly in the text is a radical change from the traditional critical apparatus paradigm and it raises interesting challenges in terms of visualization. Experimental work in the MEI community has been done on this. The MEISE editor is one such. Its development focused from the beginning on MEI features, such as editorial markup, that are not supported by existing music notation software applications. In MEISE, the variants can be selected directly from the XML tree.<note xml:id="pugin-ftn28" n="28"><ptr target="https://de.dariah.eu/mei-score-editor"/></note> 
               Another project is the meiView web application, which is an experimental project for displaying variants in 15<hi rend="sup">th</hi> and 16<hi rend="sup">th</hi> century music.<note xml:id="pugin-ftn29" n="29"><ptr target="https://zolaemil.github.io/meiView"/></note> 
               It uses VexFlow as a rendering engine and provides a solution for the user to interact with the variants. Wherever a variant occurs in the score, a green dot is displayed and clicking on it shows a pop-up with all the variants listed. A variant can then be selected from the list.</p>
            <p>In terms of design, it seems difficult to conceive a solution that would be appropriate for the visualization of any type of variant, in particular because of the high variability in terms of variant scope. Visualizing note pitch variants will quite likely require a different solution from variants in articulation. Variants where the difference is the insertion or deletion of measures will require completely different approaches, and so will variants that are permutations of entire sections. In some cases, it may make sense to be able to select a specific variant reading, but not always. Selecting one variant reading may sometimes yield results that are musically nonsense. The appropriate solution will be different from one edition case to another.</p>
            <p>Verovio does not provide any ready-to-use solution for variant visualization. In that regard, it follows the MEI philosophy and remains application agnostic. Just as MEI aims to provide a general framework for encoding music documents, so the goal of Verovio is to provide a generic solution for rendering MEI without making strong assumptions on the visualization setting or the interface design. Verovio is a rendering engine developed as a software component and not an end-user application. The interface design is left to the application development.</p>
            <p>Not providing a ready-to-use solution does not mean not providing anything, quite on the contrary. In fact, there is no need to provide a ready-to-use interface for variant visualization and interaction in Verovio because it already provides <hi rend="italic">de facto</hi> a generic foundation for this: its SVG output.</p>
            <p>With a printed edition, it is not possible to display everything in the score. Variants have to be presented separately in a critical apparatus. Similarly, variants encoded directly in the text in parallel can rarely be displayed all together (unless for very basic variants with limited scope). Consequently, Verovio is designed to render only one reading at a time.<note xml:id="pugin-ftn30" n="30">The variant selection is performed by passing an XPath expression matching the desired reading. Otherwise, the first reading (or the lemma if any) will be displayed.</note> 
               There may appear to be nothing in the notation rendered by Verovio that indicates the existence of a variant, but in fact this is not the case. Thanks to the preserved MEI structure and the MEI-SVG element mapping, the SVG tree includes a graphic XML element <gi>g</gi> for both the corresponding <gi>app</gi> and <gi>rdg</gi> MEI elements. This feature is available for variants, but also potentially for any editorial markup of MEI. By editorial markup we  mean <gi>corr</gi>, <gi>sic</gi>, <gi>unclear</gi> for encoding corrections, apparently incorrect or unclear content, or markup for encoding the writing process such as <gi>add</gi> or <gi>del</gi> for insertions and deletions, for example. Having the editorial markup preserved in the output tree makes it very easy to develop interactive applications on top of it. Only to give one example, a very basic CSS operation on the SVG can highlight all the <gi>corr</gi> elements in the rendering.</p>
            <figure xml:id="pugin-fig03">
               <graphic url="figures/pugin-fig03.png" width="1318px" height="582px"/>
               <head type="legend">Verovio can be embedded in web applications and CSS manipulations can be used for highlighting desired elements in the notation</head>
            </figure>
            <p>The fact that Verovio renders only one variant at a time is no limitation. Indeed, even if not displayed, all variant readings exist in the SVG output. The output of Verovio includes in the SVG tree a graphic XML element <gi>g</gi> for each variant, including those that are not displayed. This means that the foundation Verovio provides for editorial markup interaction is invisible but exhaustive and fully accessible at any time. This is not only valid for the content of an <gi>app</gi> element, but with any segmentation appearing in the encoding, for example when encoding alternative content with a <gi>choice</gi> element. </p>
            <figure xml:id="pugin-fig04">
               <graphic url="figures/pugin-fig04.pdf" width="1200px" height="1658px"/>
               <head type="legend">Editorial markup is preserved in the SVG output for further interaction, including the elements that are not displayed (rdg-001)</head>
            </figure>
            <p>The variant or alternative content that is currently not rendered is represented in the output and is accessible. It can be highlighted via CSS, or made clickable, for example. This is the true unrevealed interactive power of Verovio and it opens up completely new possibilities of interacting with the encoding.</p>
         </div>
         <div xml:id="pugin-div05">
            <head>Outlook</head>
            <p>The basis for interactivity offered by MEI coupled with Verovio follows some important design principles.<ref type="bibl" target="#DelTurco2011" xml:id="pugin-ftn31" n="31"/>
               First for all, the principle of availability and discoverability. That is, all the content (e.&#8239;g., all the variants) is available.  Alternative text can be made discoverable, for example with CSS highlighting. It also follows the design principle of scalability. Verovio is light and fast. It can run on small devices, but it also supports large files in higher resource environments.<note xml:id="pugin-ftn32" n="32">Typically viewing a MEI file corresponding to the equivalent of couple of hundred pages of music.</note>
            </p>
            <p>In addition, the approach proposed by MEI and Verovio fulfills several design principles specific to digital edition environments. They include the need to have good hyper-textual functionalities, which in the case of Verovio is closely linked to the discoverability principle. Alternative content can be accessed through links, for example for switching variants. </p>
            <p>There are also some technical principles that are followed as far as possible. They include reusability and durability. By providing only the interaction foundation and not making any assumption in interface design, especially with a software library that has no dependencies, reusability is undeniably maximized. So is the durability, although durability is hard to predict in software development, particularly for digital humanities projects which have slow development cycles in comparison with the development of the technology itself. Reducing dependencies as much as possible is one way to increase durability. In the case of MEI rendering, keeping the rendering engine separate from larger applications that will use it is another way.</p>
            <p>In terms of editions and interface design, there is much still to invent. This will need to be done hand in hand with the development of MEI. It is obvious that merely imitating printed output in a digital environment will not be satisfactory. Most effort should be spent on developing the added value that digital environments can offer. In parallel with the development of the online world is the appearance of new devices, such as tablets with wireless network access. They offer new possibilities in terms of digital access and change the manner and location in which digital content can be read. Developing these possibilities will not preclude the co-existence of printed editions, which have and will continue to retain their own added value. The challenge now is neither to replicate nor to supplant existing media or applications, but to expand horizons by exploring new ways of conceiving the information to which we have access, and MEI and Verovio are a decisive and exciting step in this direction.</p>
         </div>
      </body>
      <back>
         <div type="bibliography">
            <listBibl>
               <bibl xml:id="Rasch2005">Rudoll Rasch (Ed.), <title level="m">Music Publishing in Europe 1600–1900. Concepts and Issues, Bibliography</title>, Berlin 2005</bibl>
               <bibl xml:id="Hewlett1986">Walter B. Hewlett and Eleanor Selfridge-Field (Eds.), <title level="m">Computing in Musicology: A Directory of Research</title>, Menlo Park, CA, &#x00A0;2 (1986) and 3&#x00A0;(1987)</bibl>
               <bibl xml:id="SelfridgeField1997">Eleanor Selfridge-Field, <title level="m">Beyond MIDI: The Handbook of Musical Codes</title>, Cambridge 1997</bibl>
               <bibl xml:id="Nienhuys2003">Han Wen Nienhuys and Jan Nieuwenhuizen, <title level="a">LilyPond, a system for automated music engraving</title>, in: <title level="m">Colloquium on Musical Informatics (XIV CIM 2003)</title>, May 2003</bibl>
               <bibl xml:id="Freeman2010">Jason Freeman and Andrew Colella, <title level="a">Tools for Real-Time Music Notation</title>, in: <title level="j">Contemporary Music Review</title>&#x00A0;29 (2010), Special Issue: <title>Virtual Scores and Real-Time Playing</title>, p.&#8239;101–113, DOI: <ref target="http://doi.org/10.1080/07494467.2010.509599">10.1080/07494467.2010.509599</ref></bibl>
               <bibl xml:id="Fober2012">Dominique Fober, Yann Orlarey and Stéphane Letz, <title level="a">INScore – An environment for the design of live music scores</title>, in: <title level="m">Proceedings of the Linux Audio Conference</title> 2012</bibl>
               <bibl xml:id="WonLee2013">Sang Won Lee and Jason Freeman, <title level="a">Real-time music notation in mixed laptop–acoustic ensembles</title>, in: <title level="m">Computer Music Journal</title>&#x00A0;37/4 (2013), p.&#8239;24–36, DOI: <ref target="http://doi.org/10.1162/COMJ_a_00202">10.1162/COMJ_a_00202</ref></bibl>
               <bibl xml:id="Hajdu2015">Georg Hajdu, <title level="a">Dynamic notation: A solution to the conundrum of non-standard music practice</title>, in: <title level="m">Proceedings of the TENOR Conference</title> 2015</bibl>
               <bibl xml:id="Baird2005">Kevin C. Baird, <title level="a">Real-time generation of music notation via audience interaction using Python and GNU Lilypond</title>, in: <title level="m">Proceedings of the International Conference on New Interfaces for Musical Expression</title> 2005, p.&#8239;240–241</bibl>
               <bibl xml:id="Pugin2014">Laurent Pugin, Rodolfo Zitellini and Perry Roland, <title level="a">Verovio: A library for engraving MEI music notation into SVG</title>, in: <title level="m">Proceedings of the ISMIR Conference</title> 2014, p.&#8239;107–112<bibl type="short">Pugin et al., <title level="a">Verovio</title></bibl></bibl>
               <bibl xml:id="Daudin2009">Christophe Daudin, Dominique Fober, Stéphane Letz and Yann Orlarey, <title level="a">The Guido Engine: A toolbox for music scores rendering</title>, in: <title level="m">Proceedings of Linux Audio Conference</title> 2009, p.&#8239;105–111</bibl>
               <bibl xml:id="Grier1996">James Grier, <title level="m">The Critical Editing of Music: History, Method, and Practice</title>, Cambridge University Press 1996</bibl>
               <bibl xml:id="Appel2005-Pugin">Bernhard R. Appel, <title level="a">Variatio delectat – Variatio perturbat</title>, in: <title level="m">Varianten – Variants – Varientes</title>, ed. by Christa Jansohn and Bodo Plachta, Tübingen 2005 (Beihefte zu editio&#x00A0;22), p.&#8239;7–24, DOI: <ref target="http://dx.doi.org/10.1515/9783110926941.7">10.1515/9783110926941.7</ref></bibl>
               <bibl xml:id="DelTurco2011">Roberto Rosselli Del Turco, <title level="a">After the editing is done: Designing a Graphic User Interface for digital editions</title>, in: <title level="j">Digital Medievalist</title>&#x00A0;7 (2011), URL: <ptr target="http://www.digitalmedievalist.org/journal/7/rosselliDelTurco/"/></bibl>
               <bibl xml:id="Powell2007">Steven Powell, <title level="m">Music Engraving Today: The Art and Practice of Digital Notesetting</title>, New York 2007</bibl>
               <bibl xml:id="Ross1987">Ted Ross, <title level="m">Teach yourself the art of music engraving. A complete manual, reference and text book on preparing music for reproduction and print</title>, Miami 1987 </bibl>
               <bibl xml:id="Gould2011">Elaine Gould, <title level="m">Behind Bars: The Definitive Guide to Music Notation</title>, London 2011</bibl>
               <bibl xml:id="VanOrden2001">Kate van Orden (Ed.), <title level="m">Music and the Cultures of Print</title>, New York 2000 (Critical and cultural musicology&#x00A0;1)</bibl>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
